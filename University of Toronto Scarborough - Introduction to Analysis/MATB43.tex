\documentclass[12pt]{article}

\usepackage{upgreek}

\usepackage{amsmath}

\usepackage{amsthm}

\usepackage{graphicx}
\graphicspath{ {imgs/} }

\usepackage{dsfont}

\usepackage{mathtools}

\usepackage{hyperref}

\usepackage[utf8]{inputenc}

\usepackage{mathtools}

\usepackage{textcomp}

\usepackage[english]{babel}

\usepackage{tikz}

\usepackage{tcolorbox}

\usepackage{amsthm,amssymb}

\setlength{\parindent}{0cm}

\renewcommand\qedsymbol{$\blacksquare$}

\usepackage{fancyhdr}
 
\pagestyle{fancy}
\fancyhf{}
\fancyhead[LE,RO]{Introduction to Analysis -- Winter 2018}
\fancyhead[RE,LO]{Joshua Concon}
\fancyfoot[CE,CO]{\leftmark}
\fancyfoot[LE,RO]{\thepage}

\theoremstyle{plain}

\newtheorem*{remark}{Remark}
\newtheorem*{note}{Note}
\newtheorem{theorem}{Theorem}[section]

\theoremstyle{definition}

\newtheorem{definition}[theorem]{Definition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{example}[theorem]{Example}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{property}[theorem]{Property}

\begin{document}

\title{MATB43: Introduction to Analysis\\ Lecture Notes}
\date{University of Toronto Scarborough -- Winter 2018}
\author{Joshua Concon}
\maketitle
Pre-reqs are MATA37. Instructor is John Scherk. If you find any problems in these notes, feel free to contact me at conconjoshua@gmail.com.

\tableofcontents

\pagebreak

\section{Friday, January 5, 2018}

\subsection{Countability}

Countability is all about the cardinality of sets

\begin{definition}
	For sets $X,Y$, they have the same cardinality if there exists a bijection between them ($f:X\mapsto Y$ has an inverse as well). Equality of cardinality of 2 sets is written as $card(X) = card(Y)$
\end{definition}

\begin{example}
	$card(\{ 1,2,3,4,5 \}) = card(\{ a,b,c,d,e \}) $
\end{example}
\begin{example}
	$card(\mathbb{N}) = card(2\mathbb{N})$
\end{example}

This example is correct because $f:\mathbb{N} \mapsto 2\mathbb{N}, f(n)=2n$ is a bijection.

\begin{example}
	$card(\{\text{set of odd numbers}\}) = card(\mathbb{N})$
\end{example}

This example is correct because $g:\mathbb{N} \mapsto \{\text{set of odd numbers}\}\\ g(n)=2n+1, n\in\mathbb{N}$

\begin{definition}
	$X$ is \textbf{finite} if for some $n\in\mathbb{N}$ there exists a bijection where $A=\{ 1,2,...,n \}$ $f:A\mapsto X$. So essentially $card(A) = card(X)$
\end{definition}

Intuitively, we can label the elements of $X$ as $X = \{ x_1, x_2, ..., x_n \}$

\begin{definition}
	$X$ is \textbf{inifinite} if $X$ is not finite.
\end{definition}

Examples of this include: $\mathbb{N}, 2\mathbb{N}, \mathbb{Q}, \mathbb{R}$

However, not all infinite sets have the same cardinality.

\begin{definition}
	$X$ is \textbf{countable} if $card(X) = card(A)$ where $A \subseteq \mathbb{N}$
\end{definition}

Again intuitively, we can label the elements of $X$ as $X = \{ x_1, x_2, ..., x_n, ... \}$ (using elements of $\mathbb{N}$)

\begin{example}
	$2\mathbb{N}$
\end{example}

\begin{example}
	The set of odd numbers
\end{example}

\begin{example}
	$\mathbb{Z}$
\end{example}

\begin{theorem}
	In general, if $Z=X \cup Y$ and $Y,X$ are both countable then $Z$ is countable as well
\end{theorem}

\begin{proof}
	label elements of $X = \{ x_1, x_2, ..., x_n, ... \}$\\
	label elements of $Y = \{ y_1, y_2, ..., y_n, ... \}$\\
	define $h:\mathbb{N}\mapsto \mathbb{Z}$ as, for $n\in\mathbb{N}$:\\
	$$h(2n-1)=x_n$$
	$$h(2n)=y_n$$
	Then $h$ is a bijection, therefore $Z$ is also countable
\end{proof}

\begin{example}
	$\mathbb{N} \times  \mathbb{N}$
\end{example}

This example is countable as we can label its elements in the following pattern.

$$(1,1) \mapsto 1$$
$$(2,1) \mapsto 2$$
$$(1,2) \mapsto 3$$
$$(1,3) \mapsto 4$$
$$(2,2) \mapsto 5$$
$$(3,1) \mapsto 6$$
$$(4,1) \mapsto 7$$

And so on, in this pattern. Intuitively, if you list out all the pairs of $\mathbb{N} \times  \mathbb{N}$ like a matrix, this would create a sort of zig zag pattern.

\begin{proposition}
	Suppose $X$ is countable and $Y \subset X$, then $Y$ is either finite (which also means that it is countable) or just countable
\end{proposition}

\begin{proof}
	write $X = \{ x_1, x_2, ..., x_n, ... \}$\\
	let $j_1$ be the smallest index such that $x_{j_1} \in Y$\\
	let $j_2$ be the smallest index such that $x_{j_2} \in Y, j_2 > j_1$\\
	let $j_3$ be the smallest index such that $x_{j_3} \in Y, j_3 > j_2$\\
	...\\
	and so on.\\
	\\
	Now either:\\
	\textbf{This process terminates}, which means that $Y = \{ x_{j_1} , ..., x_{j_n} \}$ for some $j_1, ..., j_n$ which $Y$ is finite.\\
	\\
	or:\\
	\textbf{Y is countable}, since $Y = \{ x_{j_1}, x_{j_2} ,..., x_{j_n}, ... \}$
\end{proof}

\begin{proposition}
	$\mathbb{Q}$ is countable
\end{proposition}

\begin{proof}
	Note that $\mathbb{Q} = \mathbb{Q}^- \cup \{ 0 \} \cup \mathbb{Q}^+$\\
	so we must check that $\mathbb{Q}^+$ is countable, note that
	$$\mathbb{Q}^+ = \{ \frac{m}{n} | m,n \in \mathbb{N}, n \neq 0 \}$$
	
	Since it is a pairing of two natural numbers $(m,n)$, this is a subset of $\mathbb{N} \times \mathbb{N}$, which means that $\mathbb{Q}^+$ is countable, we can say that same thing for $\mathbb{Q}^-$ as well, note that it is
	$$\mathbb{Q}^+ = \{ \frac{-m}{n} | m,n \in \mathbb{N}, n \neq 0 \}$$
	and since $\mathbb{Q}^+$ and $\mathbb{Q}^-$ are both countable and $\{ 0 \}$ is a set of cardinality 1, therefore $\mathbb{Q}$ is countable
\end{proof}

\begin{theorem}
	Let $S = \{ s=(s_1, s_2, ...) | s_j = 0 \text{ or } 1 \forall j \}$ (note here that $s$ is a sequence). Then $S$ is not countable
\end{theorem}

\begin{proof}
	For proof by contradiction, suppose $S$ is countable.\\
	We can then label the elements of $S$ as $S^1, S^2, ... , S^n, ... \in S$.\\
	\textbf{So an example of this would be:}\\
	$$S^1 = (s^1_1, s^1_2, s^1_3, ..., s^1_n, ...)$$
	$$S^2 = (s^2_1, s^2_2, s^2_3, ..., s^2_n, ...)$$
	$$...$$
	$$S^m = (s^m_1, s^m_2, s^m_3, ..., s^m_n, ...)$$
	$$...$$
	And we will define a $t\in S$ as follows, let $t= (t_1, t_2,..., t_m, ...)$\\
	$$t_1 = \begin{cases}0, &\text{if $S^1_1=1$}\\
				1, &\text{if $S^1_1=0$}
				\end{cases}$$
	$$t_2 = \begin{cases}0, &\text{if $S^2_2=1$}\\
				1, &\text{if $S^2_2=0$}
				\end{cases}$$
	$$...$$
	$$t_m = \begin{cases}0, &\text{if $S^m_m=1$}\\
				1, &\text{if $S^m_m=0$}
				\end{cases}$$
	$$...$$
	Therefore $t \neq S^m, \forall m$. Therefore this is a contradiction as $t$ was not in the listed elements of $S$, therefore $S$ is not countable.
\end{proof}

\begin{corollary}
	$\mathbb{R}$ is not countable
\end{corollary}

\begin{proof}
	Regard $\mathbb{R}$ as a set of infinite decimal fractions.\\
	Identify $s\in S$ with the decimal number $0.s_1 s_2 ...s_n ...$ so $S$ can be regarded as a subset of $\mathbb{R}$. If $\mathbb{R}$ were countable, then $S$ would be countable, therefore $\mathbb{R}$ must not be countable.
\end{proof}

\subsection{Real Numbers}

Examples of real numbers that are not rational include: $\pi, e$ (which are algebraic numbers), $\sqrt{2}, \sqrt{3}, \frac{\sqrt{5}+1}{2}$ (which are roots of polynomial equations with integer coefficients.)

\subsection{Algebraic Numbers}

The set of Algebraic Numbers is a set $\overline{\mathbb{Q}}$ such that
$$\overline{\mathbb{Q}} = \{ x\in \mathbb{R} | x^n+ a_{n-1} x^{n-1} + ... + a_0 = 0 \text{ for some } a_0,...,a_{n-1} \in \mathbb{Z} \}$$

Note that $\mathbb{Q} \subset \overline{\mathbb{Q}}$, and in fact, $\overline{\mathbb{Q}}$ is countable.\\
\\
if $x \in (\mathbb{R} \setminus \overline{\mathbb{Q}})$ then. $x$ is transcendental.

\subsection{Bounds}

\begin{definition}
	$X \subset \mathbb{R}, X$ is \textbf{bounded above} if $\exists a \in \mathbb{R}$ such that $a \geq x, \forall x \in X$
\end{definition}

\begin{definition}
	$X \subset \mathbb{R}, X$ is \textbf{bounded below} if $\exists a \in \mathbb{R}$ such that $a \leq x, \forall x \in X$
\end{definition}

\begin{example}
	$X = \{ x\in\mathbb{R} | x^2 \leq 2 \}$ is bounded above by $\frac{3}{2}$ since $(\frac{3}{2})^2 \geq 2$
\end{example}

\begin{definition}
$a$ is the \textbf{least upper bound} of $X$ if $a$ is an upper bound of $X$ and if $b<a$, then there exists $x\in X$ such that $x > b$.
\end{definition}

We write $a = lub(X)$ or $a=sup(X)$ if $a$ is the least upper bound of $X$

\begin{definition}
$a$ is the \textbf{greatest lower bound} of $X$ if $a$ is an lower bound of $X$ and if $b>a$, then there exists $x\in X$ such that $x < b$.
\end{definition}

\begin{example}
	if $X= \{ x | x^2 \leq 2 \}$, then $sup(X)=\sqrt{2} \not\in \mathbb{Q}$
\end{example}

\begin{property}
	if $X \subset \mathbb{R}$ is bounded above then there exists $a\in\mathbb{R}$, a least upper bound of X
\end{property}

\begin{theorem}
	given $a,b\in\mathbb{R}$ $a,b>0$ $\exists n \in \mathbb{N}$ such that $na > b$ (This is known as the \textbf{archemedian property})
\end{theorem}

\begin{proof}
	Suppose that $\forall n \in \mathbb{N}$, $na \leq b$ implies that $b$ is an upper bound for $X = \{ na | n\in\mathbb{N} \}$.\\
	\\
	Since $X$ is bounded above, let $c=sup(X)$, this implies that $c-a$ is not an upper bound for $X$, which further implies that there exists an $a\in\mathbb{N}$ such that $na > c-a$, and that
	\begin{align*}
		na &> c-a\\
		na+a &> c\\
		(n+1)a &> c\\
		c < (n+1)a \in X
	\end{align*}
	
	This is impossible since we've previously stated that $c$ is the upper bound. Therefore $X$ is not bounded above.
\end{proof}

\begin{theorem}
	given $c,d\in\mathbb{R}$, there exists $q = \frac{m}{n} \in\mathbb{Q}$ such that $c< q <d$
\end{theorem}

\begin{proof}
	We want $c < \frac{m}{n} < d $ iff $nc < m < nd$.\\
	let $\epsilon = d-c > 0$\\
	pick $n\in\mathbb{N}$ such that $\frac{1}{n} < \epsilon$\\
	pick $m$, such that $m > nc$\\
	(since we also need $m<nd$, choose $m$ to be as small as possible such that $m-1 \leq nc < m$)
	
	\begin{align*}
		m-1 &\leq nc \leq m\\
		\frac{m}{n} - \frac{1}{n} = \frac{m-1}{n} &\leq c \leq \frac{m}{n}
	\end{align*}
	 or
	 $$\frac{m}{n} \leq c+\frac{1}{n} < c + \epsilon =d$$
	 So now we have $c < \frac{m}{n} < d$ as desired.

\end{proof}

\newpage

\section{Monday, January 8, 2018}

\subsection{Sequences - Review}

This section will be just review of MATA37 and will be concerning sequences of the real numbers $\{ a_n \}$.

\begin{example}
    $\{ \frac{1}{n} \} = 1,\frac{1}{2}, \frac{1}{3}, ..., $
\end{example}

\begin{example}
    $\{ \frac{(-1)^n}{n} \} = -1,\frac{1}{2}, \frac{-1}{3}, ..., $ This sequence oscillates back and forth.
\end{example}

\begin{example}
    $\{ (-1)^n \} = -1,1,-1,1, ..., $ This sequence oscillates back and forth aswell.
\end{example}

\begin{example}
    $\{ x_1, x_2, ...  \}$ where this sequence enumerates $\mathbb{Q}$. This sequence 'bounces around wildy'.
\end{example}

\begin{definition}
    $x\in\mathbb{R}$ is the \textbf{limit of a sequence $\{x_n \}$} (so that in converges to this number)\\
    $\lim_{n\to\infty} x_n = a$, if given some tolerance $\epsilon > 0$.\\
    There exists $N$, such that $n \geq N$ will lie in the interval $a-\epsilon, a+\epsilon$, aka $|x_n - a| < \epsilon$.
\end{definition}

\begin{example}
    $\lim_{n\to\infty} \frac{1}{n} = 0$
\end{example}

\begin{example}
    $\lim_{n\to\infty} \frac{(-1)^n}{n} = 0$
\end{example}

\begin{example}
    example 2.4 and 2.3 both have no limit
\end{example}

\begin{proposition}
    If a sequence $\{x_n \}$ has a limit, then this limit is unique, and the sequence is bounded.
\end{proposition}

\begin{proposition}
    Supposed that $\{x_n \} , \{y_n \} \subset \mathbb{R} $ are convergent sequences, so that $\lim_{n\to\infty} x_n = a$, $\lim_{n\to\infty} y_n = b$ then:
    \begin{enumerate}
        \item $\{x_n + y_n \}$ converges and $\lim_{n\to\infty} (x_n + y_n) = a+b$
        \item $\{x_n y_n \}$ converges and $\lim_{n\to\infty} (x_n y_n) = ab$
        \item if $y_n \neq 0, \forall n$, and $b\neq 0$ then $\{\frac{x_n}{y_n} \}$ converges and $\lim_{n\to\infty} ( \frac{x_n}{y_n}) = \frac{a}{b}$
    \end{enumerate}
\end{proposition}

\begin{definition}
    A sequence is \textbf{monotone} if it is either increasing, or decreasing.
\end{definition}

\begin{proposition}
    A bounded monotone sequence converges.
\end{proposition}

\begin{proof}
    Suppose that $\{x_n \}$ is a bounded increasing (monotone) sequence, such that
    $$x_1 \leq x_2 \leq x_3 \leq ...$$
    And there exists $A\in\mathbb{R}$ such that $x_n \leq A, \forall n$\\
    Therefore, there exists a least upper bound $a \leq A$.\\
    \\
    \underline{claim:} $x_n \to a$ as $n \to \infty$\\
    \\
    take $\epsilon > 0$, since $a$ is the least upper bound of $\{ x_n \}$, there exists $N$ such that $a-\epsilon < x_N \leq a$. But $\{ x_n \}$ is increasing. Therefore $\forall n \geq N, a-\epsilon < x_N \leq x_n \leq a$. This implies that $\lim_{n\to\infty} x_n = a$
\end{proof}

\newpage

\section{Friday, January 12, 2018}

\subsection{Monotone Sequences}

\underline{i.e.} Sequences which are increasing or decreasing

\begin{proposition}
    A bounded monotone sequence converges.
\end{proposition}

\begin{proof}
    For an increasing sequence $\{ x_n \}, \lim_{n\to\infty} x_n = sup(\{ x_n \})$, suppose $\{ x_n \}$ is decreasing and bounded below, then $\{ -x_n \}$ is increasing and bounded above. This implies that $\lim_{n\to\infty} -x_n$ and $\lim_{n\to\infty} x_n$ both exist, and $$\lim_{n\to\infty} x_n = \lim_{n\to\infty} -x_n$$
\end{proof}

So now we're going to prove that Every sequence has a monotone subsequence along with other propositions on bounded monotone sequences. This will allow us to prove the Bolzano-Weierstrass Theorem, which states that every bounded sequence has a convergent subsequence, and this will help us prove the Cauchy property for sequences.

\begin{example}
    Lets look at the following sequence:
    $$x_n = 1 + \frac{1}{2} + ... + \frac{1}{n} - logn, n\geq 1$$
    So we want to show that this converges, we'll show that if we show that $\{ x_n \}$ is decreasing and is bounded below by 0.\\
    \\
    The limit ($\lim_{n\to\infty} x_n$) is actually a mysterious number that we don't know too much about.
    
    \begin{tcolorbox}
    \underline{Recall:} that $logn = \int^n_1 \frac{dt}{t}$\\
    So if we consider the space under the graph of $\frac{1}{t}$ from $n$ to $n+1$, we get the following inequality
    
    $$\frac{1}{n+1} < log(n+1) - logn < \frac{1}{n}$$
    Which implies that
    $$\frac{1}{n+1} - log(n+1) + logn < 0$$
    
    \end{tcolorbox}
    Now consider the following for an arbitrary $n$
    $$x_{n+1} = x_n + (\frac{1}{n+1} + logn - log(n+1))$$
    but since $\frac{1}{n+1} - log(n+1) + logn < 0$, this would mean that $x_{n+1} < x_n$, so this sequence is decreasing.\\
    \\
    Now consider the following inequality derived from the recall block:
    $$\sum^m_{n=1}(log(n+1) - logn) < \sum^m_{n=1}\frac{1}{n}$$
    The left side of this inequality telescopes, giving us
    $$log(m) < log(m+1) < 1 + \frac{1}{2} + ... + \frac{1}{m}$$
    And since the left most side is greater than the right most side, that means that $x_m > 0, \forall m$.
    
\end{example}

\subsection{Subsequences}

\begin{definition}
    Let $\{ x_i \}$ be a sequence of the real numbers, pick a finite set of indices $j_1 < j_2 < ... < j_n < ....$.\\
    A \textbf{Subsequence} of $\{ x_i \}$ is $\{ x_{j_1}, x_{j_2}, ..., x_{j_n},... \}$
\end{definition}

\begin{example}
    Considering the sequence $\{ x_n \} = \{ 1,\frac{1}{2}, \frac{1}{3}, ..., \frac{1}{n}, ... \}$
    
    \begin{enumerate}
        \item $\{ \frac{1}{2n} \}$ is a subsequence of $\{ x_n \}$.
        \item $\{ \frac{1}{2^n} \}$ is a subsequence of $\{ x_n \}$.
        \item $\{ (-1)^n \}$ is also a subsequence of $\{ x_n \}$, note that it does not converge, but has convergent subsequences of $\{ (-1)^{2n} \}$ and $\{ (-1)^{2n+1} \}$
    \end{enumerate}
\end{example}

\begin{definition}
    Call a term $x_m$ \textbf{dominant} if $x_n \leq x_m, \forall n \geq m$
\end{definition}

\begin{proposition}
    Every real number sequence has a monotone subsequence
\end{proposition}

\begin{proof}
    There are 2 cases:\\
    \underline{Case 1: infinitely many dominant terms}\\
    let $\{ x_{j_1}, x_{j_2}, ..., x_{j_n},... \}$ be the sequence of dominant terms. By definition, $x_{j_1} \geq x_{j_2} \geq ... \geq x_{j_n} \geq...$\\
    so $\{ x_{j_n} \}$ is a decreasing sequence, which is monotone.
    \\
    \\
    \underline{Case 2: only finitely many dominant terms}\\
    Pick an index $j$, so that $x_{j_1}$ is the first term beyond all dominant terms in the sequence $(\exists i, i<j_1, x_i \text{ is the last dominant term})$.\\
    Since $x_{j_1}$ is not dominant, then $\exists j_2 > j_1$ where $x_{j_2} > x_{j_1}$\\
    Since $x_{j_2}$ is not dominant, then $\exists j_3 > j_2$ where $x_{j_3} > x_{j_2}$\\
    ...\\
    and so on\\
    By induction, we construct an increasing subsequence $\{ x_{j_m} \}$ of $\{ x_n \}$.\\
    \\
    By these 2 cases, every real number has a monotone sequence.
    
\end{proof}

\begin{theorem}
    (Bolzano-Weierstrass Theorem) every bounded sequence has a convergent subsequence
\end{theorem}

\begin{proof}
    Given a bounded sequence $\{ x_n \}$ of the real numbers, there exists a monotone subsequence $\{ x_{j_n} \}$.\\
    The monotone subsequence $\{ x_{j_n} \}$ is also bounded since $\{ x_n \}$ is bounded.\\
    This implies that $\lim_{n\to\infty} x_{j_n} $ exists.
\end{proof}

\begin{definition}
    \textbf{Cauchy Property:} intuitively, in a convergent sequence, the terms get closer and closer as $n\to\infty$. More precisely:\\
    $\{ x_n \}$ is a real number sequence, given $\epsilon > 0, \exists N$ such that for $m,n > N, |x_m - x_n|<\epsilon$.
\end{definition}

\begin{proposition}
    Suppose that $\{ x_n \}$ converges to $a$, then $\{ x_n \}$ satisfies the Cauchy property.
\end{proposition}

\begin{proof}
    given $\epsilon > 0$, then $\exists N$ such that $\forall n > N, |x_n - a| < \frac{\epsilon}{2}$, so if $m > N$ then $|x_m - a| < \frac{\epsilon}{2}$ as well.\\
    This implies that
    $$|x_m - x_n| = |x_m -a + a - x_n| \leq |x_m -a| + |x_n-a| < \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon$$
\end{proof}

So now we want to show that if a sequence satisfies the Cauchy property, then it converges. We'll do this by first showing that a bounded sequence with the Cauchy property implies that sequence has a convergent subsequence. The second and final step is to show that the limit of a convergent subsequence is the limit of the original sequence.\\
\\
\begin{proposition}
    If $\{ x_n \}$ satisfies the Cauchy property, then it's bounded.
\end{proposition}

\begin{proof}
    By definition, there exists $N$ so that for $m,n > N, |x_m - x_n| <1$ in particular, $\forall n > N, |x_n - x_{N+1}| < 1$, which gives us:
    \begin{align*}
        -1 <& x_n - x_{N+1} < 1\\
        x_{N+1}-1 <& x_n < x_{N+1}+1
    \end{align*}
    
    \underline{Note:} $x_{N+1}$ is fixed (a constant)\\
    \\
    Let $A = min\{ x_1, .... ,x_N, x_{N+1}-1 \}$\\
    Let $B = max\{ x_1, .... ,x_N, x_{N+1}-1 \}$\\
    This implies that for all $n$, $A \leq x_n \leq B$, therefore Bounded.
    
\end{proof}

\begin{proposition}
    A sequence with the Cauchy property is convergent.
\end{proposition}

\begin{proof}
    Let $\{ x_n \}$ be a sequence with the Cauchy property.\\
    Since $\{ x_n \}$ is bounded, by the Bolzano--Weiestrass Theorem, there exists a convergent subsequence $\{ x_{j_m} \}$. Now let:
    $$a = \lim_{m\to\infty} x_{j_m}$$
    given $\epsilon, \exists M$ so that for all $m > M, |x_{j_m} - a| < \frac{\epsilon}{2}$.\\
    \\
    \underline{Note that $j_m \geq m$}\\
    \\
    The Cauchy propert implies that $\exists N$ so that for all $m,n > N, |x_m - x_n| < \epsilon$.\\
    \\
    We'll pick $P = max(N,M)$, then for $m,n > P$ we have:
    
    \begin{align*}
        |x_n - a| &= |x_n + x_{j_m} - x_{j_m} - a|\\
        &= |x_n - x_{j_m}| + |x_{j_m} - a|\\
        &< \frac{\epsilon}{2} + \frac{\epsilon}{2}\\
        &= \epsilon
    \end{align*}
\end{proof}

\begin{example}
    $$x_n = \sum^n_{k=1} \frac{1}{k^2}$$
    Verify the Cauchy property.\\
    \\
    Take $m>n, x_m - x_n = \sum^m_{k-n+1} \frac{1}{k^2}$. Now $\frac{1}{k} < \frac{1}{k(k-1)} = \frac{1}{k-1} - \frac{1}{k}$. This implies that
    \begin{align*}
        &\implies \sum^m_{k-n+1} \frac{1}{k^2} < \sum^m_{k-n+1} (\frac{1}{k-1} - \frac{1}{k})\\
        &\overset{\text{telescoping}}{\implies} \sum^m_{k-n+1} \frac{1}{k^2} < \frac{1}{m} - \frac{1}{n} < \frac{1}{m}\\
        &\implies (x_m - x_n) < \frac{1}{m}\\
    \end{align*}
    This implies that $x_n$ is convergent, in fact
    $$\lim_{n\to\infty} x_n = \sum^\infty_{k=1} \frac{1}{k^2} = \frac{\pi^2}{6}$$
\end{example}

\newpage

\section{Monday, January 15, 2018}

\subsection{Cauchy}

\begin{remark}
	Let $\{ x_n \}$ be a sequence of real numbers. Given $\epsilon > 0$, there exists $N$ such that for $m,n > N, |x_m- x_n|<\epsilon$. If $\{ x_n \}$ converges then $\{ x_n \}$ satisfies the cauchy property.

\end{remark}

The converse also holds. So if $\{ x_n \}$ satisfies the cauchy property, then it converges. But why? It holds because:
\begin{enumerate}
	\item $\{ x_n \}$ must be bounded
	\item Therefore it has a convergent subsequence $\{ x_{j_m} \}$, assume  $\{ x_{j_m} \}$ converges to $a$.
	\item Then $\{ x_n \}$ converges to $a$ as $n\to\infty$
\end{enumerate}

\subsection{Series}

This section will be focused on 
\begin{definition}
$$\sum^\infty_{n=0} a_n$$ which is an \textbf{infinite sum} of real numbers
\end{definition}

\begin{definition}
	The following is a \textbf{partial sum}:
	$$S_n = \sum^n_{k=0} a_k$$
\end{definition}

\begin{definition}
	The series $\sum^\infty_{n=0} a_n$ converges if $\lim_{n\to\infty} S_n$ exists. If $\lim_{n\to\infty} S_n = a$, then we write $a = \sum^\infty_{n=0} a_n$  as the \textbf{Sum of the series}. However, if $\lim_{n\to\infty} S_n$ does not exist, then the series diverges.
\end{definition}

\begin{example}
	The geometric series $\sum^\infty_{n=0} a^n$ converges if $|a|<1$ and diverges otherwise. If the series does converge, it converges to:
	$$\sum^\infty_{n=0} a^n = \frac{1}{1-n}$$
\end{example}

\begin{property}
	If $\sum^\infty_{n=0} a_n$, $\sum^\infty_{n=0} b_n$ both converge, then
	$$\sum^\infty_{n=0} a_n + \sum^\infty_{n=0} b_n = \sum^\infty_{n=0} (a_n + b_n)$$
	converges as well.
\end{property}

\begin{property}
	$\forall c$, if $\sum^\infty_{n=0} a_n$ converges, then
	$$c\sum^\infty_{n=0} a_n = \sum^\infty_{n=0} c(a_n)$$
	Also converges
\end{property}

\begin{definition}
	The \textbf{Cauchy Criterion} states that $\sum^\infty_{n=0} a_n$ converges iff $\forall \epsilon > 0, \exists N$ such that $m>n > N$
	$$|S_m - S_n|=|\sum^m_{k=n+1} a_k|<\epsilon$$
\end{definition}

\begin{example}
	Apply Cauchy Criterion to $\sum^\infty_{n=0} \frac{1}{n^2}$ and $\sum^\infty_{n=0} \frac{1}{n(n+1)}$
\end{example}

To prove they converge, we first need the following proposition:

\begin{proposition}
	Suppose $\sum^\infty_{n=0} a_n$ converges, then $a_n \to 0$ as $n\to\infty$
\end{proposition}

\begin{proof} (Using the Cauchy Criterion)\\
Given $\epsilon > 0$, there exists $N$ such that for $m > n > N, |\sum^m_{k=n+1} a_k|<\epsilon$, take $m=n+1$, this implies that $|a_{n+1}|<\epsilon$ for all $n > N$, this then implies that $a_n \to 0$
\end{proof}

\begin{proposition}
	Suppose $a_n \geq 0$ then $\sum^\infty_{n=0} a_n$ converges iff $\{ S_n \}$ is bounded above.
\end{proposition}

\begin{proof}
	Since $a_n \geq 0, \forall n$, then $\{ S_n \}$ is increasing. Therefore $\lim_{N\to\infty} S_N$ exists iff $\{ S_n \}$ is bounded above.
\end{proof}

\begin{example}
	$$\sum^\infty_{n=0} \frac{1}{n}, S_N = 1 +... + \frac{1}{N} > log(N), log(N)\to\infty \text{ as } n\to\infty$$
\end{example}

\subsubsection{Convergence Tests}

\begin{definition}
	\underline{The Integral Test:} let $f$ be a function defined for $x \geq 1$ and is integrable. Let $a_n = f(n), \forall n \in\mathbb{N}$ then $sum^\infty_{n=0} a_n$ converges iff
$$\int^\infty_1 f(x) dx = \lim_{y\to\infty} \int^y_1 f(x) dx$$ exists
\end{definition}

\begin{example}
	Consider $f(x)=x^a, a\in\mathbb{R}, a\neq -1$
	$$\int^y_1 x^a dx = \left.\frac{x^{a+1}}{a+1}\right|^y_1 = \frac{x^{y+1}}{y+1} - \frac{1}{a+1}$$
	So now we know that $\int^y_1 x^a dx$ exists iff $a < -1$, so equivalently:
	$$\sum^\infty_{a=1} \frac{1}{n^a} \text{ converges iff } a > 1$$
\end{example}

\newpage

\section{Friday, January 19, 2018}

\subsection{Series (continued)}

\subsubsection{Convergence Tests}

\begin{definition}
	The \textbf{Comparison Test} is: Given a series $\sum^\infty_{k=1} a_k$ converges and $a_k \geq 0$. A series $\sum^\infty_{k=1} b_k$ converges if $|b_k| \leq a_k, \forall k$ 
\end{definition}

\begin{definition}
	The \textbf{Ratio Test} is given a series $\sum^\infty_{k=1} a_k$, consider
	$$\lim_{k\to\infty} |\frac{a_{k+1}}{a_k}| = r$$
	if $r=1$, the test is inconclusive, if $r > 1$ the series diverges, if $if r < 1 $ the series converges.
\end{definition}

\begin{example}
	Consider $\sum^\infty_{k=1} \frac{c^k}{k!}, c\in\mathbb{R}$\\
	So we will apply to the ratio test to this:
	\begin{align*}
		\lim_{k\to\infty} |\frac{(c^{k+1}/(k+1)!)}{(c^k/k!)}| &= \lim_{k\to\infty} |\frac{c^{k+1}k!}{c^k (k+1)!}|\\
		&= \lim_{k\to\infty} \frac{c}{k+1}\\
		&=
	\end{align*}
	Therefore this series converges
\end{example}

\begin{note}
	$$\sum^\infty_{k=1} \frac{c^k}{k!} = e^c$$
\end{note}

Series that contain both positive and negative terms can behave strangely

\begin{example}
	$$\sum^\infty_{k=1} \frac{(-1)^n}{n} = log(2)$$
\end{example}

\begin{definition}
	$\sum^\infty_{k=1} a_k$ \textbf{converges absolutely} if $\sum^\infty_{k=1} |a_k|$ converges
\end{definition}

\begin{definition}
	$\sum^\infty_{k=1} a_k$ \textbf{converges conditionally} if it converges but does not converge absolutely
\end{definition}

\begin{example}
	$\sum^\infty_{k=1} \frac{c^k}{k!}$ converges absolutely
\end{example}

\begin{example}
	$\sum^\infty_{k=1} \frac{(-1)^k}{k}$ converges conditionally since $\sum^\infty_{k=1} \frac{1}{k}$
\end{example}

Series that converge absolutely act like finite sums, you can rearrange the order of their terms and get the same sum, but this is not the case for conditional convergent series.

\begin{proposition}
	If a series converges absolutely, then it converges.
\end{proposition}

\begin{proof}
	Use the Cauchy Criterion. Given $\sum^\infty_{k=1} a_k$ converges absolutely, suppose $\epsilon > 0$, we have the following inequality because of the triangle inequality
	$$|\sum^m_{k=n+1} a_k| \leq |\sum^m_{k=n+1} (|a_k|) |$$
	now $\sum^\infty_{k=1} |a_k|$ converges, therefore, this satisfies the Cauchy Criterion, and so 
	$$\exists N | \forall m,n > N, \sum^m_{k=n+1} |a_k| < \epsilon \implies |\sum^m_{k=n+1} a_k|<\epsilon$$
	Therefore $\sum^\infty_{k=1} a_k$ satisfies Cauchy Criterion and converges
\end{proof}

\begin{definition}
	Given $\sum^\infty_{k=1} a_k$ as a series of positive and negative terms, let:
	
	$$a_k^+ = \begin{cases}
		a_k, &\text{ if } a_k \geq 0\\
		0, &\text{ if } a_k < 0
	\end{cases}
$$
$$a_k^- = \begin{cases}
		a_k, &\text{ if } a_k \leq 0\\
		0, &\text{ if } a_k > 0
	\end{cases}
$$
\end{definition}

\begin{note}
	$a_k = a_k^+ + a_k^-$, $|a_k| = a_k^+ - a_k^-, \forall k$
\end{note}

\begin{proposition}
	$\sum^\infty_{k=1} a_k$ converges absolutely iff $\sum^\infty_{k=1} a_k^+$ and $\sum^\infty_{k=1} a_k^-$ both converge
\end{proposition}

\begin{proof}
	So if we know that
	$$\sum^\infty_{k=1} a_k = \sum^\infty_{k=1} a_k^+ + \sum^\infty_{k=1} a_k^-$$
	$$\sum^\infty_{k=1} |a_k| = \sum^\infty_{k=1} a_k^+ - \sum^\infty_{k=1} a_k^-$$
	This implies the following 2 equations:
	$$\sum^\infty_{k=1} |a_k| + \sum^\infty_{k=1} a_k = 2\sum^\infty_{k=1} a_k^+$$
	$$-\sum^\infty_{k=1} |a_k| + \sum^\infty_{k=1} a_k = 2\sum^\infty_{k=1} a_k^-$$
	And we know that these statements only hold true of they all converge.
\end{proof}


\begin{proposition}
	if $\sum^\infty_{k=1} a_k$ converges conditionally then $\sum^\infty_{k=1} a_k^+$, $\sum^\infty_{k=1} a_k^-$ both diverge.
\end{proposition}

\begin{proof}
	Suppose only one of $\sum^\infty_{k=1} a_k^+, \sum^\infty_{k=1} a_k^-$ diverges, this implies that $\sum^\infty_{k=1} |a_k|, \sum^\infty_{k=1} a_k$ diverge.
	
	So conditional convergence must imply that both $\sum^\infty_{k=1} a_k^+, \sum^\infty_{k=1} a_k^-$ diverge since we need $\sum^\infty_{k=1} |a_k|$ to diverge, but $\sum^\infty_{k=1} a_k$ to converge. We get this from looking at the following equations from the previous proof:
	$$\sum^\infty_{k=1} a_k = \sum^\infty_{k=1} a_k^+ + \sum^\infty_{k=1} a_k^-$$
	$$\sum^\infty_{k=1} |a_k| = \sum^\infty_{k=1} a_k^+ - \sum^\infty_{k=1} a_k^-$$
\end{proof}

\begin{remark}
	Suppose $a_k \geq 0, \forall k$ and $\sum^\infty_{k=1} a_k$ converges, then since $a_k \geq 0, |a_k| = a_k$ so the series converges absolutely.\\
	\\
	Now if we change the signs of the terms arbitrarily, the new series still converges.
\end{remark}

\subsection{Alternating Series}

\begin{definition}
	Suppose $a_k \geq a_{k+1} \geq 0, \forall k \geq 1$ then
	$$\sum^\infty_{k=1} (-1)^{k+1} a_k$$ converges, this is an example of an \textbf{Alternating Series}
\end{definition}

\begin{example}
	$\sum^\infty_{k=1} \frac{(-1)^{k+1}}{k}$
\end{example}

\begin{definition}
	$$S_n = \sum^\infty_{k=1} (-1)^{k+1} a_k$$
	Is the \textbf{Partial Sum of an Alternating Series}
\end{definition}

Partial Sums of alternating series also have the following properties:

\begin{property}
	$S_2 \leq S_4 \leq ... \leq S_{2k}$
\end{property}

\begin{proof}
	We know that $S_{2k+2} = S_{2k} + (a_{2k+1} - a_{2k+2})$ and that $a_{2k+1} \geq a_{2k+2}$, this implies that $a_{2k+1} - a_{2k+2} \geq 0$, therefore $S_{2k+2} \geq S_{2k}$
\end{proof}

\begin{property}
	$S_1 \geq S_3 \geq ... \geq S_{2k+1}$
\end{property}

\begin{proof}
	We know that $S_{2k+1} = S_{2k-1} + (-a_{2k} + a_{2k+1})$ and that $a_{2k} \geq a_{2k+1}$, this implies that $-a_{2k} + a_{2k+1} \leq 0$, therefore $S_{2k+1} \geq S_{2k-1}$
\end{proof}

\begin{property}
	for an even $l$ and an odd $m$, $S_l \leq S_m$
\end{property}

\begin{proof}
	if $l=2k, m=2j+1, k,j \in \mathbb{N}$. Pick $i$ such that $i \geq j,k$ so that $2i \geq 2k = l$ and $2i+1 \geq 2j+1 = m$. This implies that $S_{2i} \geq S_{l}, S_{2i+1} \leq S_m$.
	So now $$S_{2i+1} = S_{2i} + a_{2i+1}$$
	But since $a_{2i+1} \geq 0$, this implies that $S_{2i+1 \geq S_{2i}}$
\end{proof}

And now, we'll prove that alternating series where $a_k$ decreases converges:

\begin{proof}
	Now $S_2, S_4, ... , S_{2k},...$ forms an increasing sequence, bounded above by all $S_{2k+1}$.\\
	\\
	Let $a = \underset{k}{sup}(\{ S_{2k} \})$, which implies that $a \leq S_{2k+1}$\\
	\\
	Similarly, $S_1, S_3, ... , S_{2k+1}$ forms a decreasing sequence, bounded below by all $S_{2k}$, $a$ is also a lower bound of $\{ S_{2k+1} \}$. Let $b= \underset{k}{inf} (\{ S_{2k+1} \})$
\end{proof}

\newpage

\section{Monday, January 22, 2018}

\subsection{Alternating continued}

$$\sum^\infty_{k=1} a_k \text{ converges absolutely if } \sum^\infty_{k=1} |a_k| \text{ converges}$$

$$\sum^\infty_{k=1} a_k \text{ converges conditionally if it converges but not absolutely }$$

\begin{example}
The alternating harmonic series converges, but not absolutely.
\end{example}

\subsection{Rearrangement}

Because of this, we can rearrange the terms in the series to get it to converge to any number we want.

\begin{example}
	For the alternating harmonic series, we separate all the terms into 2 groups, those that are positive and those that are negative, and we can add them in a way that makes the series converge to, let's say, 2.
	\\
	\\
	For example, we can add up all the positive terms until we get to $\frac{1}{15}$, where adding $\frac{1}{15}$ brings the sum over 2 and not adding $\frac{1}{15}$ keeps the sum below 2, so we set
	$S_1$ to be all the decreasing positive terms until $\frac{1}{15}$, and then we will add increasing negative terms until the sum is below 2 to get $T_1$, and we add decreasing terms until the sum is above 2 and so on and so forth. This makes $S_{k+1} < S_k, \forall k$, $T_{k+1} > T_k, \forall k$.
	
\end{example}

\begin{theorem}
	If $sum^\infty_{k=1} a_k$ converges conditionally, then for any $b\in\mathbb{R}$, there exists an rearrangement for the series where its sum is $b$.
\end{theorem}

\underline{Recall:} Series of positive and negative terms of $\sum a_k$

$$a_k^+ = \begin{cases}
		a_k, &\text{ if } a_k \geq 0\\
		0, &\text{ if } a_k < 0
	\end{cases}
$$
$$a_k^- = \begin{cases}
		a_k, &\text{ if } a_k \leq 0\\
		0, &\text{ if } a_k > 0
	\end{cases}
$$

and $a_k = a_k^+ + a_k^-$, and if $\sum a_k$ is convergent, the both $\sum a_k^+$ and $\sum a_k^-$ diverge. So either the positive sum approaches infinity or the negative sum approaches negative infinity as more of their terms are added together, and at the same time, $a_k$ approaches 0.

\begin{proof}
	Choose an $N$ such that 
	$$\sum^{N_1}_{k=1} a^+_k > b > \sum^{N_1 - 1}_{k=1} a^+_k$$
	Set $S_1 = \sum^{N_1}_{k=1} a^+_k, S_1 - b < a^+_{N_1}$\\
	Choose $M_1$ so that
	
	$$T_1 = S_1 + \sum^{M_1}_{k=1} a^-_k < b \leq S_1 + \sum^{M_1 - 1}_{k=1} a^-_k$$
	And continue this pattern to get the rearranged series:
	
	$$a^+_1,...,a^+_{N_1}, a^-_1, ... a^-_{M_1}, a^+_{N_1 + 1}, ... a^+_{N_2},...$$
	With $|S_k - b| < a^+_{N_k}, |T_k - b| < -a^-_{M_k}$\\
	$$a^+_{N_k}, a^-_{M_k} \text{ as } k \to \infty$$
	So $S_k \to b$ from above and $T_k \to b$ from below.
\end{proof}

\begin{theorem}
	Suppose that 
	$\sum^\infty_{k=1} a_k$ is absolutely convergent and $b = \sum^\infty_{k=1} a_k$ then any rearrangement of this series will also have the sum of $b$.
\end{theorem}

\newpage

\section{Monday, January 29, 2018}

\subsection{Rearrangement (continued)}

\begin{theorem}
	Suppose $\sum^\infty_{k=1} a_k$ is absolutely convergent, let $\sum^\infty_{k=1} b_k$ be a rearrangement, then it has the same sum as the original series
\end{theorem}

\begin{proof}
	Let $a = \sum^\infty_{k=1} a_k$\\
	Pick $\epsilon > 0$\\
	Since $\sum^\infty_{k=1} |a_k|$ converges, then there exists an $M$ such that $\sum^\infty_{k=M+1} |a_k| = \sum^\infty_{k=1} |a_k| - \sum^M_{k=1} |a_k| < \frac{\epsilon}{2}$
	Now let
	$$\{ a_1, a_2, ... a_M \} \subset \{ b_1, b_2, ... b_N \} \text{ for some } N \geq M $$
	Be true for some sequence $\{b_k \}$. This implies that
	$$(\{ b_1, b_2, ... b_N \} \setminus \{ a_1, a_2, ... a_M \})  \subset \{ a_{M+1}, a_{M+2}, .... \}$$
	Let us set $s_M = \sum^M_{k=1} a_k, t_N =  \sum^N_{k=1} b_k$
	
	$$|t_N - s_M| \leq  \sum^M_{k=M+1} a_k < \frac{\epsilon}{2}$$
	Now
	\begin{align*}
		|a - t_N| &\leq |s_N - a| + |s_M - t_N|\\
		&\leq  \frac{\epsilon}{2} +  \frac{\epsilon}{2}\\
		&= \epsilon
	\end{align*}
	Therefore $\sum^\infty_{k=1} b_k = a = \sum^\infty_{k=1} a_k$
\end{proof}

\begin{theorem}
	$e$ is irrational
\end{theorem}

\begin{proof}
	We know that $e = \sum^\infty_{k=0} \frac{1}{k!}$. Suppose that e is rational, then $e = \frac{a}{b}, a,b\in\mathbb{Z}, b \neq 0$. Then.
	$$(b+1)! \sum^{b+1}_{k=0} \frac{1}{k!} \in \mathbb{N}, (b+1)!e \in \mathbb{N}$$
	This implies that
	\begin{align*}
	&\Longrightarrow (b+1)! \sum^\infty_{k=b+2} \frac{1}{k!} \in \mathbb{N}\\
	&= (b+1)! (\frac{1}{(b+2)!} + \frac{1}{(b+3)!} + ...)\\
	&= (\frac{1}{(b+2)} + \frac{1}{(b+2)(b+3)} + ...)\\
	&<  (\frac{1}{(b+2)} + \frac{1}{(b+2)^2} + ...)\\
	&=  \sum^\infty_{k=1} \frac{1}{(b+2)^k}\\
	&= \frac{1}{(b+2)}(\frac{1}{1 - \frac{1}{b+2}})\\
	&= \frac{1}{(b+2)}(\frac{b+2}{(b+1)}) = \frac{1}{(b+1)} < 1
	\end{align*}
	This is a contradiction, therefore $e$ must be irrational

\end{proof}

\subsection{Power Series}

Another convergence test: The root test

\begin{definition}
	(The root test) given $\sum^\infty_{k=1} a_k$, consider $\lim_{k\to\infty} |a_k|^{\frac{1}{k}}$, if $\lim_{k\to\infty} |a_k|^{\frac{1}{k}}$ exists and it's less than 1, then it converges, if it's greater than 1, then it diverges.
\end{definition}

We can apply this test to power series.

\begin{theorem}
	Given $\sum^\infty_{k=1} a_k x^k$, let $c=\lim_{k\to\infty} |a_k|^{\frac{1}{k}}$, $R = \frac{1}{c}, c\neq 0$ then $\sum^\infty_{k=1} a_k x^k$ converges for $|x| <R$ if $R<1$ and $\sum^\infty_{k=1} a_k x^k$ diverges if $|x| > R$
\end{theorem}

So basically, for $x \in (-R, R)$ the series converges, and for $x \not\in [-R, R]$ the series diverges. $x = \pm R$ is still unknown

\begin{proof}
	apply the root test
	\begin{align*}
		\lim_{k\to\infty} (| a_k x^k |)^{\frac{1}{k}} &= \lim_{k\to\infty} | a_k |^{\frac{1}{k}} |x|\\
		&= |x| \lim_{k\to\infty} | a_k |^{\frac{1}{k}}\\
		&= |x| \cdot c
	\end{align*}
	The root test implies that the series converges if $|x|\cdot c < 1$ and this implies that $|x| < \frac{1}{c} = R, c \neq 0$ And the series diverges if $|x| c > 1$ which happens iff $|x| > R$
	
\end{proof}

\begin{remark}
	if $c=0$ $(R = \infty)$ then $\sum^\infty_{k=0} a_k x^k$ converges for all $x \in \mathbb{R}$.\\
	\\
	if $\lim_k |a_k|^{\frac{1}{k}}$ then series only converges for $x=0$
\end{remark}

\begin{example}
	$sum^\infty_{k=0} \frac{x^k}{k!}, R = \infty$
\end{example}

\begin{example}
	$sum^\infty_{k=0} x^k, R=1$, if $x=\pm 1$ then the series diverges
\end{example}

\begin{example}
	$sum^\infty_{k=1} \frac{x^k}{k}$ apply the ratio test, $R =1$, $|(\frac{x^{k+1}}{k+1}) (\frac{k}{x^k})| = |x| \frac{k}{k+1}$
	so when $x=1$, $sum^\infty_{k=1} \frac{x^k}{k}$ diverges
	and when $x=-1$, $sum^\infty_{k=1} \frac{x^k}{k}$ converges
\end{example}

\begin{example}
	$sum^\infty_{k=1} \frac{x^k}{k^2}, R=1$ and this converges for $x=\pm 1$  
\end{example}

\newpage

\section{Friday, February 2, 2018}

\subsection{Pointwise and Uniform Convergence}

Consider a sequence of functions $f_1, ... ,f_k, ...$ defined on $S \subset \mathbb{R}$\\

\begin{definition}
$\{ f_k \}$ converges \textbf{pointwise} to a function $f$ on $S$ if for any $x_0 \in S, \{ f_k (x_0) \} \to f(x_0)$

\end{definition}

\begin{example}
	$f_n (x) = \frac{sin(nx)}{x}, x\in\mathbb{R}$\\
	
	We know that $\lim_{n\to\infty} \frac{sin(n x_0)}{n} = 0, x_0 \in\mathbb{R}$ as
	$\frac{|sin(n x_0)|}{n} \leq \frac{1}{n} \to 0$ as $n$ approaches infinity.\\
	\\
	if $f(x) = 0$ for all $x\in\mathbb{R}$, then $f_n$ converges pointwise to $f$.
\end{example}

\begin{example}
	$f_n (x) = \frac{nx}{1 + n^2 x^2}, x \geq 0$, $f(x) = 0$, for $x \geq 0$
	\\
	$f_n$ converges pointwise to $f$.\\
	\\
	This is because $f_n (x) < \frac{nx}{n^2 x^2} = \frac{1}{nx}, x > 0$ so for $x_0 > 0, 0 < f_n (x_0) < \frac{1}{n x_0} \to 0$, as $n$ approaches infinity.\\
	\\
	For $x_0 = 0, f_n (x_0) \to f(x_0) = 0$
\end{example}

\begin{note}
	For $x_0 = \frac{1}{n}, f_n (\frac{1}{n}) = \frac{1}{2}$
\end{note}

\begin{definition}
	A sequence of functions $\{ f_n \}$ converges to a function $f$ \textbf{uniformly} on $S$ if given $\epsilon > 0$, there exists $N$ such that for $n \geq N$
	$$|f_n (x_0) = f(x_0)| < \epsilon, \forall x_0 \in S$$
\end{definition}

\begin{example}
	Consider $f_n (x) = 1+ x + ... + x^n$,$ f(x)=\frac{1}{1-x}$ if $|x| < 1$.\\
	\\
	We know that $f_n (x_0) \to f(x_0)$ for any $x_0 \in (-1, 1)$
\end{example}

\begin{note}
	$f_n \to f$ uniformly, means that sequences $f_n (x_0) \to f(x_0)$ "at the same rate", for all $x_0$
\end{note}

\begin{example}
	$f_n (x) =  \frac{nx}{1 + n^2 x^2} < \frac{1}{nx}, x \geq 0$, take $\epsilon = \frac{1}{4}$
	(we're looking for how big $n$ has to be for the function $f_n$ to be less than $\frac{1}{4}$)\\
	\\
	if $x_0 = \frac{1}{10}$, then $\frac{1}{n 10^{-1}} = \frac{10}{n} < \frac{1}{4}$, for $n > 40$\\
	\\
	if $x_0 = \frac{1}{100}$, then $\frac{1}{n 10^{-2}} = \frac{100}{n} < \frac{1}{4}$, for $n > 400$\\
	\\
	if $x_0 = 10^{-6}$, then $\frac{1}{n 10^{-6}} = \frac{10^6}{n} < \frac{1}{4}$, for $n > 4 \times 10^6$\\
	The differences in the rate of convergence is exponential the bigger the $n$. So $f_n (\frac{1}{10})$, $f_n (\frac{1}{100})$, $f_n (10^{-6})$, do not converge at the same rate.
\end{example}

\begin{example}
	$S = [1,0]$, $f_n (x) = x^n$,
	$$f(x) = \begin{cases}
		0, &0 \leq x < 1\\
		1, &x = 1
	\end{cases}
$$
if we take different values of $n$ for $f_n$, they seem to drop down steeper as they go close to $1$, but also rise up steeper as they approach closer to $1$, there is a bit of a dip.\\
\\
$\{ x_0^n \} \to 0, 0 \leq x_0 < 1$. $f_n$ converges pointwise to $f$.\\
Note that $f_n$ is continuous for all of $n$, but $f$ is not continuous.
\end{example}

\begin{example}
	verify that $f_n \to f$ uniformly in example 1.\\
	$f_n (x) = \frac{sin(nx)}{n}, f(x) = 0, \forall x \in \mathbb{R}$\\
	\\
	given $\epsilon > 0$,
	$$|\frac{sin(nx)}{n}| < \frac{1}{n}$$
	So choose $N$, with $\frac{1}{N} < \epsilon$, this implies that for all $n \geq N, |\frac{sin(nx)}{n}| < \frac{1}{n} < \epsilon, \forall x \in \mathbb{R}$
\end{example}

\begin{theorem}
	Suppose $f_n \to f$ uniformly on $S \subset \mathbb{R}$, If $f_n$ is continuous for all $n$, then $f$ is continuous
\end{theorem}

\begin{proof}
	Need to show $f$ is continuous at any $x_0 \in S$, take $\epsilon > 0$, we need to find $\delta > 0$ so that for $|x - x_0| < \delta$, that $|f(x) - f(x_0)| < \epsilon$\\
	\\
	Since $f_n \to f$ uniformly, there exists $N$ so that for $n \geq N$, $|f_n (x) - f(x)| < \frac{\epsilon}{3}$ for all $x\in S$\\
	\\
	$f_N$ is continuous at $x_0$, therefore there exists a $\delta > 0$ such that for $|x-x_0| < \delta$ then $|f_N (x) - f_N (x_0)| < \frac{\epsilon}{3}$\\
	\\
	now
	\begin{align*}
		|f(x) - f(x_0)| & \leq |f(x) - f_N (x)| + |f_N (x) - f_N (x_0)| + |f_N (x_0) - f(x_0)|\\
		&< \frac{\epsilon}{3} + \frac{\epsilon}{3} + \frac{\epsilon}{3} = \epsilon
	\end{align*}
	This is because of the uniform convergence for $|f(x) - f_N (x)|, |f_N (x_0) - f(x_0)|$ and continuity of $F_N$ for $|f_N (x) - f_N (x_0)|$\\
	\\
	this implies that for $|x - x_0| < \delta$, that $|f(x) - f(x_0)| < \epsilon$.
\end{proof}

\begin{example}
	$S = [1,0]$, $f_n (x) = x^n$,
	$$f(x) = \begin{cases}
		0, &0 \leq x < 1\\
		1, &x = 1
	\end{cases}
$$
$f_n$ does not converge uniformly in this example since $f$ is not continuous at 1
\end{example}

\begin{note}
	When he have shown that the partial sums of a power series converge uniformly, then this theorem will show that the power series is continuous
\end{note}

\subsection{Integrals}

Suppose $f_n \to f$ uniformly on an interval $[a,b]\subset\mathbb{R}$ and suppose $f_n$ is integrable for all $n$, we want to show that $f$ is integrable

$$\int^b_a f(x) dx = \lim_{n\to\infty} \int^b_a f_n (x) dx$$
we're gonna assume $f_n$ are continuous on $[a,b]$ for all $n$ which implies that $f_n$ is integrable on $[a,b]$, but then $f$ continuous on $[a,b]$, this implies that $f$ is integrable.
\\
\\
Recall: if $f,g$ on $[a,b]$, they are integrable if $f \leq g$\\
\\
This implies that
$$\int^b_a f(x) dx \leq \int^b_a g(x) dx$$
which implies that for any $f$ integrable on $[a,b]$

$$|\int^b_a f(x) dx| \leq \int^b_a |f(x)| dx$$
By triangle inequality.

\begin{theorem}
	$f_n \to f$ uniformly on $[a,b]$, $f_n$ is continuous for all $n$, this implies that
	$$\int^b_a f(x) dx = \lim_{n\to\infty} \int^b_a f_n (x) dx$$
\end{theorem}

\begin{proof}
	Given $\epsilon > 0$, since $f_n \to f$ uniformly, there exists $N$ such that for $n \geq N$\\
	\\
	$$|f_n (x) - f(x)| < \frac{\epsilon}{b-a}$$
	for all $x\in [a,b]$, then
	\begin{align*}
		|\int^b_a f(x) dx - \int^b_a f_n(x) dx| &= |\int^b_a (f(x)-f_n (x)) dx|\\
		 &\leq \int^b_a f_n (x) - f(x)|dx\\
		 &\leq \int^b_a \frac{\epsilon}{b-a} dx = \epsilon
	\end{align*}
	And this implies that
	$$\int^b_a f(x) dx = \lim_{n\to\infty} \int^b_a f_n (x) dx$$

\end{proof}

\newpage

\section{Monday, February 5, 2018}

\subsection{Convergence}

\begin{definition}
	Sequence of functions $\{ f_n (x) \}, x\in S \subset \mathbb{R}$ converges pointwise to $f(x)$ on $S$ if for any $x_0 \in S$, the sequence $\{ f_n (x_0) \} \to f (x_0)$ as $n \to \infty$
\end{definition}

$f_n (x_0)$ uniformly converges if $\epsilon > 0$, there exists $N$ such that $\forall x \in S$, $|f_n (x) - f(x)| < \epsilon$ if $n > N$

\begin{example}
	on $[0,1], f_n (x) = \frac{x}{n} \leq \frac{1}{n}$. For all $x$, pick $N$ given $\epsilon$, $\frac{1}{N} < \epsilon$, then for all $n \geq N$, $f_n (x) \leq \frac{1}{n} \leq \frac{1}{N} < \epsilon$ for all $x$, this implies that on $[0,1]$, $f_n \to f$ uniformly
\end{example}

\begin{example}
	Does $f_n (x)$ from the above example converge uniformly for $x\in[0,\infty)$? No.\\
	\\
	Given $\epsilon > 0$, for any $N$, we can find $x_0$ with $\frac{x_0}{N} \geq \epsilon$, $f_n (x_0) \geq \epsilon$
\end{example}

\begin{theorem}
	Suppose $f_n \to f$ uniformly on $S$, $f_n$ continuous for all $n$, then $f$ continuous on $S$
\end{theorem}

\begin{example}
	$f_n (x) = \frac{1}{1+x^n}$
	$$\lim_{n\to\infty} = \begin{cases}
		\frac{1}{2}, &x=1\\
		1, &x \in [0,1)
	\end{cases}
$$
Since $f$ is not continuous at $1$, convergence not uniform by the theorem.
\end{example}

\begin{theorem}
	$f_n$ continuous on $[a,b] \in \mathbb{R}$, $f_n \to f$ uniformly on $[a,b]$ then that implies that
	$$\lim_{n\to\infty} \int_a^b f_n (x) dx = \int_a^b f (x) dx$$
\end{theorem}

\begin{example}
	$f(x) = \sum^\infty_{k=0} x^k, |x| < 1$ set $S_n (x) = \sum^n_{k=0} x^k$ then $S_n \to f$ pointwise, pick $a\in (0,1)$
	
	$$|S_m - S_n| = \sum^m_{k=n+1} x^k \leq \sum^m_{k=n+1} |x|^k \leq \sum^m_{k=n+1} a^k$$ if $|x| \leq a$, since $\sum^\infty_{k=0} a^k$ converges it satisfies the cauchy criterion. So, given $\epsilon > 0$, there exists $N$, such that for $m > n > N$ that
	$$\sum^m_{k=n+1} a^k < \epsilon$$
	$$\Longrightarrow |S_m (x) - S_n (x) | < \epsilon$$ for $m,n > N$ and for all $x$.
	
\end{example}

So a uniform definition version of the Cauchy Criterion is needed. A Uniform Cauchy Criterion perhaps.\\

\begin{theorem}
$\{ f_n \}$ defined on $S$, satisfies the Uniform Cauchy Criterion if given $\epsilon > 0$, there exists $N$ such that for $m,n > N$, we have $|f_n (x) - f_m (x)|< \epsilon$ for all $x\in S$.
\end{theorem}

\begin{theorem}
	Suppose $\{ f_n (x) \}$ satisfies the uniform Cauchy Criterion on $S$ then for $x_0 \in S$, $\{ f_n (x) \}$ satisfies the the cauchy property and therefore $\lim_{n\to\infty} f_n (x_0)$ exists, if $f(x_0) = \lim_{n\to\infty} f_n (x_0)$ then $f_n \to f$ uniformly on S
\end{theorem}

\begin{example}
	partial sums $S_n (x)$ of a geometric series satisfies Uniform Cauchy Criterion on $[-a, a]$ where $a \in [0,1]$, $S_n \to f$ uniformly on $[-a, a]$.
\end{example}

\newpage

\section{Friday, February 9, 2018}

\newpage

\section{Monday, February 12, 2018}

\subsection{Power Series}

\begin{definition}
	A \textbf{Power Series} is a series of the form $$f(x) = \sum^\infty_{k=0} a_k x^k$$ and if it has a radius of convergence of $R > 0$ then $f$ is continuous and differentiable on $(-R, R)$  with $$f(x) = \sum^\infty_{k=0} kx^{k-1}$$ and $$\int^x_0 f(t) dt = sum^\infty_{k=0} a_k \frac{x^{k+1}}{k+1}, x \in (-R, R)$$
\end{definition}

\begin{example}
	$\frac{1}{1-x} = sum^\infty_{k=0} x^k, |x| < 1$
	\begin{align*}
		\int^x_0 \frac{dt}{1-t} &= -log(1-x)\\
		&= sum^\infty_{k=0} \frac{x^{k+1}}{k+1} \\
		&\Longrightarrow log(1-x) = - \sum^\infty_{k=0} \frac{x^{k+1}}{k+1}, |x| <1\\
		&\Longrightarrow log(1+x) = \sum^\infty_{k=1} \frac{(-1)^{k+1} x^k}{k}
	\end{align*}
	What happens at $x=1$? Both sides define functions which are continuous at 1.
\end{example}

\begin{theorem}
	\textbf{Abel's Theorem:} Suppose $f(x) = \sum^\infty_{k=0} a_k x^k$, radius of convergence is $R > 0$, if the series converges at $R$ or $-R$ then $f$ is continuous at $R$ or $-R$.
\end{theorem}

\begin{definition}
	\textbf{Exponential Function:} $exp(x) = \sum^\infty_{k=0} \frac{x^k}{k!} = e^k$ converges for all real values of $x$\\
	\underline{properties:}
	\begin{enumerate}
		\item{$$exp ' (x) = exp(x)$$\\
		Suppose $f(x)=\sum^\infty_{k=0} a_k x^k$ converges for $|x| < R$, and $f'(x) = f(x)$, this implies that $f^n (x) = f(x)$ and that $f^n (0) = a_n$, which also implies that $a_n = \frac{a_0}{n!}$ which implies that $f(x) = a_0 exp(x)$\\
		(note: the solutions for $\frac{dy}{dx} = y$ are $c \cdot exp(x), c \in \mathbb{R}$) 
		}
		\item{
		$$exp(a+b) = exp(a)exp(b)\:\:\: a,b \in\mathbb{R}$$
		let $f(x)=exp(a+x)$
		$$\Longrightarrow f'(x) = cf(x), c \in\mathbb{R}$$
		$$exp(a+x) = c \cdot exp(x)$$ in particular for $x=0$,
		$$exp(a) = c\cdot exp(0) \Longrightarrow exp(a) = c \cdot 1 = c$$
		$$\Longrightarrow exp(a+x) = exp(a) exp(x), \forall x \in\mathbb{R}$$
		define $e = exp(1)=\sum^\infty_{k=0} \frac{1}{k!}$
		$$e^m=exp(m),m\in\mathbb{N}$$
		$l\in\mathbb{N}$ then, $exp(\frac{m}{l})^l = exp(m) = e^m$
		$$\Longrightarrow exp(\frac{m}{l}) = e^{\frac{m}{l}}$$
		$$\Longrightarrow e^q = exp(q), q \in \mathbb{Q}$$
		since $exp'(x) = exp(x) > 0$ $\Longrightarrow exp$ is increasing.\\
		For $r\in\mathbb{R}$, define $e^r = sup \{ e^q | q\in\mathbb{Q}, q < r \} = exp(r)$
		}
	\end{enumerate}

\end{definition}

$$e^x = exp(x) = \sum^\infty_{k=0} \frac{x^k}{k!}$$

\underline{Properties:}
\begin{enumerate}
	\item{
	$e^x$ is strictly increasing
	\begin{proof}
		The mean value theorem states that:
		$$e^b - e^a = (b-a) e^c$$
		for some $c\in (a,b)$, and since $ (b-a) e^c$ is always above 0, then $e^b > e^a$
	\end{proof}

	}
	\item{$\lim_{x\to-\infty} e^x = 0$
	\begin{proof}
		$$e^x > 1+x$$
		so $x\to\infty \Longrightarrow e^x\to\infty$
		$\Longrightarrow e^{-x} = \frac{1}{e^x} \to 0$ as $x\to\infty$
	\end{proof}

	}
\end{enumerate}

\newpage








\end{document}



























