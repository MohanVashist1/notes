\documentclass[12pt]{article}

\usepackage{upgreek}

\usepackage{amsmath}

\usepackage{amsthm}

\usepackage{graphicx}

\graphicspath{ {imgs/} }

\usepackage{dsfont}

\usepackage{mathtools}

\usepackage{hyperref}

\usepackage[utf8]{inputenc}

\usepackage{mathtools}

\usepackage{textcomp}

\usepackage[english]{babel}

\usepackage{tikz}

\usepackage{tcolorbox}

\usepackage{amsthm,amssymb}

\setlength{\parindent}{0cm}

\renewcommand\qedsymbol{$\blacksquare$}

\usepackage{fancyhdr}
 
\pagestyle{fancy}
\fancyhf{}
\fancyhead[LE,RO]{Multivariable Calculus II -- Winter 2018}
\fancyhead[RE,LO]{Joshua Concon}
\fancyfoot[CE,CO]{\leftmark}
\fancyfoot[LE,RO]{\thepage}

\theoremstyle{plain}

\newtheorem*{remark}{Remark}
\newtheorem*{note}{Note}
\newtheorem{theorem}{Theorem}[section]

\theoremstyle{definition}

\newtheorem{definition}[theorem]{Definition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{example}[theorem]{Example}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{property}[theorem]{Property}

\begin{document}

\title{MATB42: Multivariable Calculus II\\ Lecture Notes}
\date{University of Toronto Scarborough -- Winter 2018}
\author{Joshua Concon}
\maketitle
Pre-reqs are MATB41. Instructor is Eric Moore. If you find any problems in these notes, feel free to contact me at conconjoshua@gmail.com.

\tableofcontents

\pagebreak

\section{Friday, January 5, 2018}

\subsection{Fourier Expansions}

In this section, we will focus on single variable calculus, (so where $f:\mathbb{R} \mapsto \mathbb{R}$)\\
\\
Let us say that we have a function $f(x)$ and we want to approximate it. We can use an $n$th degree Taylor Polynomial, but this requires that $f(x)$ has at least $n$ derivatives at some point $x_0$ and the $k$th derivative of $f$ ($f^{(k)} (x)$) is determined by properties of $f$ in some neighbourhood of $x_0$, but what about outside this neighbourhood? How can we be certain of the approximation outside of this neighbour.\\
\\
Our problem here is that Taylor Polynomial may only approximate "near" $x_0$\\
\\
Now, consider the following function:

$$\Delta (x) = \begin{cases}
1, &\lfloor x \rfloor < x, \lfloor x \rfloor\text{ is odd} \\
0, &\lfloor x \rfloor < x, \lfloor x \rfloor\text{ is even}\\
\end{cases}
$$

In this function, Tayler returns either 0 or 1 depending on your choice of $x_0$ and cannot work for an $x_0 = p \in \mathbb{Z}$. Therefore Taylor polynomials cannot reflect the true nature of this function. Taylor provides a "local" approximation, but we want a "global" approximation. We need an approximation that is more precise over an interval at the cost of being not as precise as precise at any particular $x_0$.\\
\\
Note that the example function is \textbf{periodic}.\\
\\

\begin{definition}
	A function $y=f(x)$ such that $f(x)=f(x+p), p \neq 0, \forall x$ is said to be \textbf{periodic} of period $p$
\end{definition}

\begin{example}
	The periodic function $\Delta (x)$ is of period 2.
\end{example}

What we want is a global approximation of a periodic function, and the Fourier Approximation will be periodic, so we can use it for exactly that.

\begin{definition}
	A \textbf{trigonometric polynomial of degree $N$} is an expression of the form
	$$\frac{a_0}{2}+ \sum^N_{k-1} a_k cos(kx) + b_k sin(kx)$$ where the $a_i, b_i$ are constants.
\end{definition}

We know that $sin(x)$ and $cos(x)$ are the simplest periodic functions and repeat in intervals of $2\pi$, so $cos(kx)$ and $sin(kx)$ have period $\frac{2\pi}{k}$, but the smallest shared period is $2\pi$. If a trigonometric polynomial has period $2\pi$ and $f(x)$ has period $p$, then we must set $x=\frac{pt}{2\pi}$ to fix the period (where $t$ is a variable).\\
\\
So to approximate $y=f(x)$ by $F_N (x)$ for some $N$, we use the following equation:

$$F_N (x) = \frac{a_0}{2}+ \sum^N_{k=1} a_k cos(kx) + b_k sin(kx)$$

Now we need to choose the $a_k, b_k$. We can define it in the following way:

$$a_0 = \frac{1}{\pi} \int^{\pi}_{-\pi} f(x) dx$$
$$a_k = \frac{1}{\pi} \int^{\pi}_{-\pi} f(x) cos(kx) dx, k=1,2,3,...$$
$$b_k = \frac{1}{\pi} \int^{\pi}_{-\pi} f(x) sin(kx) dx, k=1,2,3,...$$

When defined in this way, $a_i, b_i$ are called the \textbf{Fourier Coefficients} of $f$ over the interval $[-\pi, \pi]$ and we call $F_N (x)$ the \textbf{Fourier Polynomial of degree $N$}.\\
\\
So why do we add the $\frac{a_0}{2}$? It is the average value of $f$ over $[-\pi, \pi]$.

\begin{note}
	sometimes you will see $a_0$ used instead of $\frac{a_0}{2}$ in the Fourier polynomial where $$a_0 = \frac{1}{2\pi} \int^{\pi}_{-\pi} f(x) dx$$
\end{note}

\begin{example}
	Consider $f(x)=\frac{-x}{2}$ over $[-\pi, \pi]$. Use Fourier Approximation.\\
	\\
	$$a_k = \frac{1}{\pi} \int^{\pi}_{-\pi} f(x) cos(kx) dx = \frac{1}{\pi} \int^{\pi}_{-\pi} (-\frac{x}{2}) cos(kx) dx \overset{odd}{=} 0$$
	$$a_0 = \frac{1}{\pi} \int^{\pi}_{-\pi} f(x) dx = \frac{1}{\pi} \int^{\pi}_{-\pi} (-\frac{x}{2}) dx \overset{odd}{=} 0$$
	\begin{align*}
		b_k &= \frac{1}{\pi} \int^{\pi}_{-\pi} f(x) sin(kx) dx\\
		&= \frac{1}{\pi} \int^{\pi}_{-\pi} (-\frac{x}{2}) sin(kx) dx\\
		&\overset{even}{=} - \frac{1}{\pi} \int^{\pi}_{-\pi}  x sin(kx) dx\\
		&\underset{u=x, dv=sin(kx)dx}{\overset{even}{=}} - \frac{1}{\pi} [-\frac{1}{k} x cos(kx) + \frac{1}{k^2} sin(kx)]^\pi_0\\
		&= \frac{1}{\pi k} [\pi cos(k\pi)]\\
		&= \frac{1}{k} cos(k\pi)\\
		&= \frac{(-1)^k}{k}
	\end{align*}
	
	Thus we have:
	$$F_N (x) = -sin(x) + \frac{1}{2}sin(2x) - \frac{1}{3}sin(3x) + \frac{1}{4}sin(4x) + ...$$
	$$F_1 (x) = -sin(x)$$
	$$F_2 (x) = -sin(x) + \frac{1}{2}sin(2x)$$
	$$F_3 (x) = -sin(x) + \frac{1}{2}sin(2x) - \frac{1}{3}sin(3x)$$
	$$...$$
	And so on.

\end{example}

\newpage

\section{Monday, January 8, 2018}

continuing from the last lecture...

\begin{example}
    (continued from example 1.4)\\
    $f(x) = \frac{-x}{2}$\\
    $F_N (x) = -sin(x) + \frac{1}{2}sin(2x) - \frac{1}{3}sin(3x) + \frac{1}{4}sin(4x) + ...$\\
    \\
    This can be extended to a Fourier Series:
    $$F_N (x) = \sum^\infty_{k=1} (-1)^k \frac{sin(kx)}{k}$$
\end{example}

\begin{definition}
    For $f:\mathbb{R}\mapsto\mathbb{R}$, the Fourier Series for $f$ is
    $$F(x) = \frac{a_0}{2}+ \sum^\infty_{k=1} a_k cos(kx) + b_k sin(kx)$$
    where $a_i, b_i$ are Fourier coefficients.
\end{definition}

The $N$th degree Fourier Polynomial can be regarded as the $N$th partial sum of the series.\\
\\
We haven't talked about convergence yet, but for now, we will assume the series converges $(f(x)=F(x))$

\begin{definition}
    Function $a_k cos(kx) + b_k sin(kx)$ is the $k$th harmonic of $f$. The Fourier Series expresses $f$ in terms of its harmonics.
\end{definition}

\begin{note}
    (Looking at Harmonics in a Musical Sense):\\
    the $1$st harmonic is the fundamental harmonic of $f$ (the fundamental tone).\\
    The $2$nd harmonic is the first overtone.
\end{note}

(completely rewrite this amplitude section)

\begin{definition}
    The amplitude of the $k$th harmonic is 
    $$A_k = \sqrt{(a_k)^2 + (b_k)^2}$$
    And note that
    $$a_k = A_k sin\alpha, b_k = A_k cos\alpha$$
\end{definition}

\begin{definition}
    The energy $E$ of a periodic function $f$ of period $2\pi$ is
    $$E = \frac{1}{\pi} \int^\pi_{-\pi} [f(x)]^2 dx$$
\end{definition}

So the energy of the $k$th harmonic is
$$E = \frac{1}{\pi} \int^\pi_{-\pi} [a_k cos(kx) + b_k sin(kx)]^2 dx = (a_k)^2 + (b_k)^2 = (A_k)^2$$

And the energy of the constant term is

$$\frac{1}{\pi} \int^\pi_{-\pi} [a_0]^2 dx = 2(a_0)^2$$
So we put $A_0 = \frac{1}{\sqrt{2}} a_0$.\\
\\
For a "nice" periodic function, we have the following equation:

$$E = A_0^2 + A_1^2 + A_2^2 + ...$$
This is known as the Energy Theorem, and comes from the study of periodic waves.\\
\\
We can draw a graph of this as $A_k^2$ against $k$ (This graph is known as the Energy Spectrum of $f$). It shows how the energy of $f$ is distributed among its harmonics.\\
\\
\begin{note}
    Notice that
    $$E = \frac{1}{\pi} \int^\pi_{-\pi} [f(x)]^2 dx = \frac{a_0^2}{2}+ \sum^\infty_{k=1} (a_k^2 + b_k^2) \text{ Parseval's Equation}$$
\end{note}

Assume a function $f$ of period $2\pi$ is the sum of a trigonometric series

$$f(x) = \frac{a_0}{2}+ \sum^\infty_{k=1} (a_k cos(kx) + b_k sin(kx)) \text{ on the interval } [-\pi,\pi]$$

Multiply by $cos(mx)$ and integrate to get
\begin{align*}
    \int^\pi_{-\pi} f(x)cos(mx) dx &= \frac{a_0^2}{2} \int^\pi_{-\pi} cos(mx) dx + \int^\pi_{-\pi} [\sum^\infty_{k=1} (a_k cos(kx) + b_k sin(kx))]dx\\
    &= \frac{a_0^2}{2} \int^\pi_{-\pi} cos(mx) dx +  \sum^\infty_{k=1} (a_k \int^\pi_{-\pi}cos(kx)dx + b_k \int^\pi_{-\pi}sin(kx)dx)
\end{align*}

\begin{note}
    Recall the following trigonometric identities:
    \begin{enumerate}
        \item $cosAcosB = \frac{1}{2} [cos(A+B) + cos(A-B)]$
        \item $cosAsinB = \frac{1}{2} [sin(A+B) + sin(A-B)]$
        \item $sinAsinB = \frac{1}{2} [cos(A-B) - cos(A+B)]$
    \end{enumerate}
\end{note}

\newpage

\section{Friday, January 12, 2018}

Continuing from where we left off.

\begin{align*}
    \int^\pi_{-\pi} f(x)cos(mx) dx &= \frac{a_0^2}{2} \int^\pi_{-\pi} cos(mx) dx + \int^\pi_{-\pi} [\sum^\infty_{k=1} (a_k cos(kx) + b_k sin(kx))]dx\\
    &= \frac{a_0^2}{2} \int^\pi_{-\pi} cos(mx) dx +  \sum^\infty_{k=1} (a_k \int^\pi_{-\pi}cos(kx)dx + b_k \int^\pi_{-\pi}sin(kx)dx)
\end{align*}

We know the following from trigonometric identities
$$\int^\pi_{-\pi} cos(kx)cos(mx) dx = \begin{cases}
    0, &k\neq m\\
    \pi, &k=m
\end{cases}$$
As well as the following from odd function properties
$$\int^\pi_{-\pi} cos(kx) dx = 0$$
$$\int^\pi_{-\pi} sin(kx)cos(mx) dx = 0$$
So now we get
\begin{align*}
    \int^\pi_{-\pi} f(x)cos(mx) dx
    &=  \frac{a_0^2}{2} \int^\pi_{-\pi} cos(mx) dx +  \sum^\infty_{k=1} (a_k \int^\pi_{-\pi}cos(kx)dx + b_k \int^\pi_{-\pi}sin(kx)dx)\\
    &= a_m \pi\\
    &\implies a_m = \frac{1}{\pi} \int^\pi_{-\pi} f(x)cos(mx) dx
\end{align*}

\begin{example}
    Lets take
    $$f(x) = \begin{cases}
    1, &0\leq x < \pi\\
    -1, &-\pi \leq x < 0
    \end{cases}$$
    
    Note that this is an odd function, therefore $a_k = 0, \forall k \geq 0$. So now lets calculate $b_k$.
    
    \begin{align*}
        b_k &= \frac{1}{\pi} \int^\pi_{-\pi} f(x)sin(kx) dx\\
        &\overset{even}{=} \frac{2}{\pi} \int^\pi_{0} f(x)sin(kx) dx\\
        &= \frac{2}{\pi} \int^\pi_{0} sin(kx) dx\\
        &= \frac{2}{k\pi} [ -cos(kx) ]^\pi_0\\
        &= \begin{cases}
            \frac{4}{k\pi}, &\text{$k$ is odd}\\
            0, &\text{$k$ is even}
        \end{cases}
    \end{align*}
    
    And now lets right out the Fourier Polynomial $(F_N (x))$\\
    \underline{if $N$ is odd:}
    $$F_N (x) = \frac{4}{\pi}sin(x) + \frac{4}{3\pi}sin(3x) + \frac{4}{5\pi}sin(5x) + ...$$
    \underline{if $N$ is even:}
    $$F_N (x) = F_{N-1} (x)$$
    We can also write it as a Fourier Series
    $$F(x) = \frac{4}{\pi} \sum^\infty_{l=0} \frac{sin((2l+1)x)}{2l+1}$$
    
    The energy of the function is
    $$E = \frac{1}{\pi} \int^\pi_{-\pi} [f(x)]^2 dx = \frac{2}{\pi} \int^\pi_0 dx = 2$$
    
    The amplitutde of the $k$th harmonic is
    $$A_k = \sqrt{a_k^2 + b_k^2} = \sqrt{0 + \frac{16}{k^2\pi^2}} = \frac{4}{k\pi}$$
    
    The energy of the $k$th harmonic is
    $$A_k^2 = \frac{16}{k^2 \pi^2}$$
    
    Note that for this example, both the energy and the amplitude are 0 at an even $k$.\\
    \\
    Lets now evaluate the energy spectrum:
    $$k=1, E= \frac{16}{\pi^2} \approx 1.62, \frac{1.62}{2}=0.81=81\%$$
    $$k=3, E= \frac{16}{9\pi^2} \approx 0.18, \frac{0.18}{2}=0.09=9\%$$
    $$k=5, E= \frac{16}{25\pi^2} \approx 0.06, \frac{0.06}{2}=0.03=3\%$$
    $$k=7, E= \frac{16}{49\pi^2} \approx 0.03, \frac{0.03}{2}=0.015=1.5\%$$
    
\end{example}

However, we do not need to exclusively work with the interval $[-\pi, \pi]$ we can even work over any interval of length $2\pi$.

\subsection{General Fourier Series (interval of length $2\pi$)}

$$a_k = \frac{1}{\pi} \int^{c+2\pi}_{c} f(x) cos(kx) dx, k=1,2,3,...$$
$$b_k = \frac{1}{\pi} \int^{c+2\pi}_{c} f(x) sin(kx) dx, k=1,2,3,...$$

What about for $f$ if $f$ has period $p$?

$$f(x+p) = f(x), \forall x, \exists p \neq 0$$

We then substitute $x = \frac{pt}{2\pi}$ which gives a new function $f_p (t) = f(\frac{pt}{2\pi})$ with period $2\pi$. So

$$f_p (t+2\pi) = f(\frac{p}{2\pi} (t+2\pi)) = f(\frac{pt}{2\pi} + p) = f(\frac{pt}{2\pi}) = f_p (t)$$

So how about the Fourier Expansion for $f_p (t)$? To find this, we must replace $t$ by $\frac{2\pi x}{p}$ giving for $f(x)$.

$$F(x) = \frac{a_0}{2}+ \sum^\infty_{k-1} a_k cos(\frac{2nx\pi}{p}) + b_k sin(\frac{2nx\pi}{p})$$
$$a_k = \frac{2}{p} \int^{c+p}_{c} f(x) cos(\frac{2nx\pi}{p}x) dx, k=1,2,3,...$$
$$b_k = \frac{2}{p} \int^{c+p}_{c} f(x) sin(\frac{2nx\pi}{p}x) dx, k=1,2,3,...$$

For any function defined on $[a,b]$, we can extend $f$ to all of $\mathbb{R}$ as a periodic function. Given a periodic function $f_E$ from $f$ of period $p=b-a$, we now have:

$$a_k = \frac{2}{b-a} \int^{b}_{a} f(x) cos(\frac{2nx\pi}{b-a}x) dx, k=1,2,3,...$$
$$b_k = \frac{2}{b-a} \int^{b}_{a} f(x) sin(\frac{2nx\pi}{b-a}x) dx, k=1,2,3,...$$

\begin{example}
    Take the function $f(x) = x, 0\leq x < 1$ and extend it with period 1. For $k\neq 0$:
    \begin{align*}
        a_k &= 2 \int^{1}_{0} xcos(2k\pi x) dx\\
        &\overset{parts}{\underset{u=v, dv=cos(2\pi kx)dx}{=}} 2[\frac{xsin(2k\pi x)}{2\pi k}]^1_0 - \frac{2}{2k \pi} \int^1_0 sin(2k\pi x) dx\\
        &=0
    \end{align*}
    $$a_0 = 2 \int^1_0 x dx = [x^2 ]^1_0$$
    \begin{align*}
        b_k &= 2\int^1_0 x sin(2k\pi x)dx\\
        &\underset{u=x, dv=sin(2k\pi x)dx}{\overset{parts}{=}} 2[\frac{-xcos(2k\pi x)}{2\pi k}]^1_0 + \frac{1}{k\pi} \int^1_0 cos(2k\pi x)dx\\
        &= \frac{-cos(2k\pi)}{k\pi}\\
        &= \frac{-1}{k\pi}
    \end{align*}
    So the Fourier Series will be
    $$F(x) = \frac{1}{2} - \frac{1}{\pi} [sin(2\pi x) + \frac{sin(4\pi x)}{2} + \frac{sin(6\pi x)}{3} + ...]$$
\end{example}

\begin{example}
    $f(x) = |x|, -\pi < x \leq \pi$. Since $f(x)$ is even, $b_k=0, \forall k\in\mathbb{N}$.
    
    $$a_0 = \frac{1}{\pi} \int^\pi_{-\pi} |x|dx \overset{even}{=} \frac{2}{\pi} \int^\pi_0 x dx= \pi$$
    
   \begin{align*}
   	a_k &= \frac{1}{\pi} \int^\pi_{-\pi} |x| cos(kx) dx\\
	&\overset{even}{=} \frac{2}{pi} \int^\pi_0 x cos(kx) dx\\
	&\underset{u=x, dv=cos(kx)dx}{\overset{parts}{=}} \frac{2}{\pi} [\frac{x sin(kx)}{k} + \frac{cos(kx)}{k^2}]^\pi_0\\
	&= \frac{2}{\pi k^2} (cos(k\pi) - 1)\\
	&=\begin{cases}
		0, &\text{$k$ is even}\\
		\frac{-4}{\pi k^2}, &\text{$k$ is odd}
	\end{cases}
   \end{align*}
   
   So we end up with the Fourier Series
   
   $$F(x) = \frac{\pi}{2} - \frac{4}{\pi} \sum^\infty_{l=0} \frac{cos((2l+1)x)}{(2l+1)^2}$$

\end{example}

\begin{example}
	$f(x) = x, -\pi < x \leq \pi$. Note that since $f(x)$ is odd, $a_k = 0, \forall k \geq 0$
	\begin{align*}
		b_k &= \frac{1}{\pi} \int^\pi_{-\pi} x sin(kx) dx\\
		&\underset{u=x, dv=sin(kx)dx}{\overset{parts}{=}} \frac{1}{\pi} [\frac{-xcos(kx)}{k}]^\pi_{-\pi} + \frac{1}{\pi} \int^\pi_{-\pi} cos(kx) dx\\
		&= \frac{1}{\pi} [\frac{-\pi cos(k\pi)}{k} + \frac{-\pi cos(-k\pi)}{k}]\\
		&= \frac{-2}{k} cos(k\pi)\\
		&= \frac{(-1)^{k+1} 2}{k}
	\end{align*}
	And the Fourier Series of this is
	$$F(x) = \sum^\infty_{k=1} (-1)^{k+1} \frac{2}{k} sin(kx)$$
\end{example}

To get a Fourier cosine series or a Fourier sine series, we need
\begin{itemize}
	\item{an $f$ defined on the interval $[0,a]$, and we must extend this interval to also include $[-a,0)$ to give an even or odd function on $[-a,a]$}
	\item{$f(-t)=f(t), -a\leq t < 0$ for the even extension}
	item{$f(-t)=-f(t), -a\leq t < 0$ for the odd extension}
\end{itemize}

\newpage

\section{Monday, January 15, 2018}

\begin{example}
	We want to express $f(x)=x, 0\leq x < \pi$ as both a cosine series and a sine series.\\
	\\
	\underline{cosine series}
	For this, we need to extend the function as an even function, so we extend the function to $f(x)=|x|, -\pi < x \leq x$. This is a previous example that we computated before and gives us a cosine series\\
	\\
	\underline{sine series}
	For this, we must extend $f(x)$ as an odd function $f(x)=x, -\pi \geq x < \pi$. We've already seen from previous examples that is a sine series.\\
	\\
	So for $f(x)=x, 0 \leq x < pi$, the cosine series looks like this:
	$$F(x) = \frac{\pi}{2} - \frac{4}{\pi} \sum^\infty_{l=0} \frac{cos((2l+1)x)}{(2l+1)^2}$$
	And the sine series looks like this:
	$$F(x) = \sum^\infty_{k=0} (-1)^{k+1} \frac{2}{k} sin(kx)$$
	Both of these series on the interval $[0,\pi)$ represent $f(x)=x$
\end{example}

\begin{definition}
	A function $f(x)$ defined for $x\in[a,b]$ is \textbf{piece-wise continuous} if there exists a finite partition $P: a=t_0< .... < t_n =b$ such that $f$ is continuous on $x\in(t_{i=1}, t_i), \forall i$ and both $\lim_{x\to t^+_{i-1}} f(x)$ and $\lim_{x\to t^-_{i-1}} f(x)$ both exist and are both finite.
\end{definition}

\begin{note}
	On the $i$th subinterval, $f(x)$ coincides with some $f_i (x)$ that is continuous on that subinterval.
\end{note}

\begin{definition}
	If $f_i (x) \forall i$ has continuous 1st derivatives, $f(x)$ is called \textbf{piecewise smooth}
\end{definition}

\begin{definition}
	If $f_i (x) \forall i$ has continuous 2nd derivatives, $f(x)$ is called \textbf{piecewise very smooth}
\end{definition}

\begin{definition}
	The Fourier Series obtained from $f(x)$ converges to $f(x)$ if $f(x) = \lim_{N\to\infty} F_N (x)$
	
	\underline{i.e.} $$f(x) = \lim_{N\to\infty} F_N (x) = \frac{a_0}{2}+ \sum^N_{k-1} a_k cos(kx) + b_k sin(kx)$$
	
	assuming a period of $2\pi$ (and can be adjusted for other periods). The $a_k$ and $b_k$ are the Fourier coefficients.
\end{definition}

\begin{theorem}
	Let $f(x)$ be continuous and piece-wise very smooth for all $x$ and let $f(x)$ have period $2\pi$. Then the Fourier Series of $f(x)$ converges uniformly to $f(x), \forall x$
\end{theorem}

This helps with examples that have jump discontinuities.

\begin{theorem}
	Let $f(x)$ be defined and piece-wise very smooth for $x\in[-\pi,\pi]$ and let $f(x)$ be defined outside this interval to have period $2\pi$. Then the Fourier Series of $f(x)$ converges uniformly to $f(x)$ in each interval containing no discontinuity of $f(x)$. At each discontinuity, $x_0$, the series converges to
	$$\frac{1}{2} [\lim_{x\to x_0^+} f(x) + \lim_{x\to x_0^-} f(x)]$$
	This is the \textbf{Fundamental Theorem (for Fourier Series)}. The Theorem can be reinstated for $f$ defined on any interval of length $p\neq 0$
\end{theorem}

\begin{example}
	\begin{enumerate}
		\item $f(x) = \frac{-x}{2}$ on the interval $[-\pi, \pi]$
		\item $f(x) = \begin{cases}
			1, &0\leq x < \pi\\
			-1, &-\pi\leq x < 0
		\end{cases}
$
	\end{enumerate}
	Note that they both are piece-wise continuous and both satisfy the previous theorem.\\
	\\
	so (1.) converges to
	$$\sum^\infty_{k=1} \frac{(-1)}{k} sin(kx) = \begin{cases}
		-\frac{x}{2}, &x\in (-\pi, \pi)\\
		0, &x = \pm \pi
	\end{cases}
$$

And (2.) converges to

$$\sum^\infty_{k=1} \frac{sin((2k+1)x)}{2k+1} = \begin{cases}
		-1, &-\pi < x < 0\\
		1, &0 < x < \pi\\
		0, &x = -\pi, 0,\pi
	\end{cases}
$$

In (2.) set $x = \frac{\pi}{2}$ and we'll get
\begin{align*}
	1 &= \frac{4}{\pi}\sum^\infty_{k=1} \frac{sin((2k+1)\frac{\pi}{2})}{2k+1}\\
	1 &=\frac{4}{\pi}\sum^\infty_{k=1} \frac{(-1)^k}{2k+1}\\
	\frac{\pi}{4}&= \sum^\infty_{k=1} \frac{(-1)^k}{2k+1}\\
	\frac{\pi}{4}&=1-\frac{1}{3}+\frac{1}{5}-\frac{1}{7}+...
\end{align*}

So now we have $\frac{\pi}{4}$ represented by a series of numbers.

\end{example}

However, the domain of the function also play a role in the series.

\begin{example}
	For $f(x), x\in[0,1)$, we get
	$$F(x) = \frac{1}{2} - \frac{1}{\pi}\sum^\infty_{k=1} \frac{sin((2k+1)x)}{2k+1}$$
	The theorem still applies and we get $F(x) = x$ on the interval $[0,1)$, and converge to $\frac{1}{2}$ at $0$. 
\end{example}

\begin{example}
	For $f(x)=|x|, x\in [-\pi,\pi]$ we get.
	$$F(x) = \frac{\pi}{2} - \frac{1}{\pi}\sum^\infty_{k=1} \frac{cos((2k+1)x)}{(2k+1)^2}$$
	on $(0,1), |x|=x$, and since $f$ is piece-wise very smooth, we can write:
	$$x=\frac{\pi}{2} - \frac{1}{\pi}\sum^\infty_{k=1} \frac{cos((2k+1)x)}{(2k+1)^2}$$
\end{example}

\section{Friday, January 19, 2018}

\begin{definition}
	The \textbf{orthonormal bases for $\mathbb{R}^n$}
	$$\{ e_1, ..., e_n \}$$
	are all orthogonal to each other and are all unit vectors.\\
	\\
	Each $v\in \mathbb{R}^n$ has a unique representation of
	$v = \lambda_1 e_1 + ... + \lambda_n e_n$ where $\lambda_k = v \cdot e_k$
\end{definition}

Given continuous functions $f,g$ that map from $[-\pi, \pi] \mapsto \mathbb{R}$ we can define an inner product by
$$<f,g> = frac{1}{\pi} \int^{\pi}_{-\pi} f(x) g(x) dx$$ defined on all continues real-valued functions defined on the interval $[-\pi, \pi] $

\begin{example}
	The set of functions $\{ cos(kx), sin(nx) \}_{n,k\in\mathbb{Z}}$ act like an orthonormal basis. since
	
	$$<cos(mx), cos(nx)> = \begin{cases}1, &\text{ if } m=n\\ 0, &\text{ otherwise} \end{cases}$$
	$$<sin(mx), sin(nx)> = \begin{cases}1, &\text{ if } m=n\\ 0, &\text{ otherwise} \end{cases}$$
	$$<sin(mx), cos(nx)> = 0$$
	
	for positive integers $m,n$
\end{example}

We can regard the Fourier Coefficients as the components of $f$ under this basis. This explains why you dont need to recalculate the coefficients for each $N$ for $F_N (x)$

\begin{corollary}
	If a function $f$ can be represented as a trigonometric polynomial, then that trigonometric polynomial is a Fourier Expansion of $f$, if the Fourier Series converges.
\end{corollary}

\begin{example}
	What is the fourier series of $f(x)=cos^2(x) - sin^2(x)$\\
	\\
	We have trigonometric identities to solve this:
	$$F(x)=cos^2(x) - sin^2(x)=cos(2x)$$
\end{example}

\begin{example}
	\begin{align*}
	f(x) &=cos^4(x)\\
	&=(cos^2(x))^2\\
	&=(cos^2(x))^2\\
	&= \frac{1}{4}(1+2cos(2x) + cos^2 (2x))\\
	&= \frac{1}{4}(1 + 2cos(2x) + \frac{1}{2} + \frac{1}{2}cos(4x))
	&= \frac{3}{8} + \frac{cos(2x)}{2} + \frac{1}{8}cos(4x) = F(x)
	\end{align*}
\end{example}

\begin{definition}
	The \textbf{Total Square Error} of $g(x)$ relative to $f(x)$ is:
	$$E = \int^\pi_{-\pi} [f(x) - g(x)]^2 dx$$
\end{definition}

\begin{note}
	if $f=g, E=0$
\end{note}

We want a constant function $y=g_0$ so the square error is as small as possible

\begin{align*}
	E(g_0) &= \int^\pi_{-\pi} [f(x) - g_0]^2 dx\\
	&= \int^\pi_{-\pi} f(x)^2 dx - 2 g_0 \int^\pi_{-\pi} f(x) dx + g_0^2 (2\pi)
\end{align*}

And if we let $A,B$ be constants such that $$A = \int^\pi_{-\pi} f(x)^2 dx, B = \int^\pi_{-\pi} f(x) dx$$

Then
$$E(g_0) = A - 2 B g_0 + 2 \pi g_0^2$$

With implies that $E(g_0)$ is a quad function in $g$ having a minimum value when its derivative is equal to 0.

$$-2B + 4\pi g_0 = 0$$

$$g_0 = \frac{B}{2\pi} = \frac{1}{2\pi} \int^\pi_{-\pi} f(x) dx = \frac{1}{2} a_0$$

Therefore $\frac{1}{2} a_0$ is the best constant approximation in the sense of the square error. We can show that the best approximation by a trigonometric polynomial is the Fourier Polynomial.

\begin{definition}
	If $f$ is piece-wise continuous on $[-\pi, \pi]$ we see that
	
	$$\frac{a_0}{2}+ \sum^N_{k=1} a_k^2 + b_k^2 \leq \frac{1}{\pi} \int_{-\pi}^\pi [f(x)]^2 dx = <f,f>$$
	This is called \textbf{Bessel's Inequality} and it shows that $\sum^\infty_{k=1} a_k^2 + b_k^2$ converges
\end{definition}

\begin{theorem}
(Uniqueness Theorem) Let $f(x), g(x)$ be piecewise continuous functions on the interval $[-\pi,\pi]$ and have all the same same Fourier coefficients. Then $f(x)=g(x)$ except, perhaps, at discontinuities.
\end{theorem}

\subsection{Vector-Valued Functions}

We will now spend time with vector-valued functions ($f:\mathbb{R}^n \mapsto A$)

\begin{definition}
	A \textbf{curve (or path)} in $\mathbb{R}^n$ is a function
	$$\gamma : [a,b] \subset \mathbb{R} \mapsto \mathbb{R}^n$$
	We usually call the image of $\gamma$ the curve and the function $\gamma$ as the parameterization of the curve
\end{definition}

\begin{note}
	This curve has a direction given by $\gamma$ and runs from $\gamma (a)$ to $\gamma (b)$, which are the endpoints. $\gamma (a)$ being the beginning and $\gamma (b)$ being the end
\end{note}

Think of $t, t\in [a,b]$ as a variable and $\gamma (t)$ as "tracing out" the curve in $\mathbb{R}$ as $t$ goes from $a$ to $b$.

This interval be adapted to any $(a,b)$ and even to $\mathbb{R}$ itself.

$$\gamma (t) = (\gamma_1 (t), \gamma_2 (t), ..., \gamma_n (t)), t\in[a,b]$$

\begin{example}
	where $t \in \mathbb{R}$
	\begin{align*}
		\gamma (t) &= (x_0, y_0, z_0) + t(v_1,v_2,v_3)\\
		&= x + tv
	\end{align*}
	This is a parametric representation of a line. Where $x$ is a point and $v$ is a direction vector

\end{example}

\begin{definition}
	$\gamma$ is \textbf{continuous} at $c\in (a,b)$ if $\lim_{t\to c} \gamma (t) = \gamma (c)$ iff the components $\gamma_i (t)$ for $i=1,...,n$ are continuous at $c$
\end{definition}

\begin{definition}
	If $\gamma$ is continuous at all points, $\gamma$ is called a \textbf{Continuous Path}
\end{definition}

\begin{example}
	Consider a circle of radius $3$ in $\mathbb{R}^2$ centred around the origin. A path of this circle is 
	$$\gamma (t) = (3cost, 3sint), t \in [0,2\pi]$$
	We say this curve is oriented in the counter clockwise direction
\end{example}

\begin{example}
	The curve for $y=x^3 +1$ is
	$$\gamma (t) = (t, t^3 +1), t\in\mathbb{R}$$
\end{example}

\begin{example}
	In $\mathbb{R}^3, \gamma (t) = (3cost, 3sint, t) , t \in [0,2\pi]$.\\
	\\
	Since $x^2 + y^2 = 9$, this curve must live in the cylinder $x^2 + y^2 = 9$ and since $z=t$, the curve spirals upwards, this is called a helix
\end{example}

\begin{example}
	$\gamma (t)= (t, t^2, t^3), t\in [-2,2]$. This is a twisted cubic.
\end{example}

\begin{example}
	Find the parameterization of the curve $C$ of the intersection of the cylinder $x^2 + y^2 = 1$ and the plane $y+z = 2$. The projection into the $x-y$ plane is the circle $x^2 + y^2 = 1, z=0$, so
	
	$$x=cost, y=sint$$
	
	From the equation of the plane
	$$z = 2-y = 2-sint$$
	We now parameterize the curve $C$ by
	$$\gamma (t) = (cost, sint, 2-sint), t\in [0,2\pi]$$
\end{example}

\section{Monday, January 22, 2018}

\begin{note}
	For any given curve, there may be several possible parameterizations of that curve
\end{note}

\begin{example}
	
\end{example} The $1$st quadrant piece of the unit circle in a counter clock-wise direction, from $(1,0)$ to $(0,1)$

$$\gamma_1 (t) = (cost, sint), t\in [0, \frac{\pi}{2}]$$
$$\gamma_2 (t) = (cos(\frac{t}{2}), sin(\frac{t}{2})), t\in [0, \pi]$$
$$\gamma_3 (t) = (\sqrt{1-t^2}, t), t\in [0, 1]$$
All parameterize the same curve.

\begin{definition}
	The \textbf{Derivative of a path} is
	$$D(\gamma(t)) = (\gamma_1'(t), \gamma_2'(t), ... , \gamma_n'(t))$$
	provided each $\gamma_i'(t)$ exists for $t=1,...,n$\\
	\\
	We usually write $\gamma' (t) = (\gamma_1'(t),...,\gamma_n'(t))$ 
\end{definition}

\begin{definition}
	If $\gamma'(t)$ exists, $\gamma$ is called a \textbf{differentiable path}
\end{definition}

\begin{definition}
	If $\gamma$ is a differentiable path with a continuous derivative, except at finitely many places, the image of $\gamma$ is called a \textbf{piece-wise smooth curve}
\end{definition}

\begin{definition}
	$\gamma'(t)$ is the tanget $v$ to the curve at the point $\gamma (t)$. Hence, the tanget line at $\gamma (t_0)$ is given by
	$$\gamma (t_0) + \lambda \gamma ' (t_0), \lambda \in \mathbb{R}$$
\end{definition}

Note that $\gamma (t)$ must be smooth (class $C^1$) for $t$ near $t_0$, be careful if $\gamma (t_0) = 0$

\begin{remark}
	If we think of $\gamma (t)$ representing the position of a particle at time $t$, we can regard $\gamma ' (t)$ as its velocity and $\gamma '' (t)$ as its acceleration.\\
	\\
	If $\gamma ' (t)$ is the velocity, then $||\gamma ' (t)||$ is the speed (magnitude of the velocity)
\end{remark}

\begin{example}
	Computing the period of a satellite when the radius of its orbit is known. The particle has constant speed $s$, and when $t=0$, assume that $\gamma (t)$ is at the point $(r,0)$.\\
	\\
	So....
	$$\gamma(t) = (rcos(kt), rsin(kt))$$
	We need to find $k$.
	$$\gamma ' (t) = (-rksin(kt), rkcos(kt))$$
	$$s = ||\gamma ' (t)|| = \sqrt{r^2 k^2 (sin^2 (kt) + cos^2 (kt))} = rk$$
	And this implies that $k = \frac{s}{r}$.\\
	\\
	Note that $r,k \in \mathbb{R}^+ > 0$
	
	$$\gamma '' (t) = (-rk^2 cos(kt), -rk^2 sin(kt)) = -k^2 \gamma (t)$$
	
	Assuming particle is a satellite of mass $m$ orbiting the earth of mass $M$.
	
	\begin{note}
		$$F = ma = m(\gamma '' (t)) = -mk^2 \gamma (t)$$
		$$F(\vec{v}) = \frac{-G m M \vec{v}}{||\vec{v}||^3}$$
		where $G$ is the gravitational constant and $\vec{v} = \gamma (t)$
	\end{note}
	
	$$-mk^2 \gamma (t) = \frac{-G m M \gamma (t)}{r^3}$$
	
	And this implies that $k^2 = \frac{GM}{r^3}$.\\
	\\
	What is the period? $p = \frac{2\pi}{k}$ this implies that $k = \frac{2\pi}{p}$.
	
	$$k^2 = (\frac{2\pi}{p})^2 = \frac{GM}{r^3}$$
	This implies that
	$$p^2 = \frac{4 \pi^2}{GM} r^3$$
	
	The period of a satellite squared is proportional to the radius of its orbit cubed (One of Kepler's Laws)

\end{example}

\begin{definition}
	The \textbf{path integral of $f$} or the \textbf{integral of $f$ along the path $\gamma$} denoted
	$$\int_\gamma f ds$$
	is defined by
	$$\int_\gamma f ds = \int^b_a f(\gamma(t)) ||\gamma ' (t) || dt$$
	Whenever $\gamma: [a,b]\mapsto \mathbb{R}^n$ is a smooth curve and the composite function $t \mapsto f(\gamma(t))$ is continuous on $[a,b]$
\end{definition}

If $\gamma (t)$ is only piece-wise smooth or $f(\gamma (t))$ is only piece-wise continuous, we break $\gamma (t)$ into finitely many smooth pieces, and sum the integrals over the various pieces.


\end{document}



























