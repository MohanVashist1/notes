——————————————————————————————————————————————————————————————————————————————————————————————————————————————
Week 1
——————————————————————————————————————————————————————————————————————————————————————————————————————————————
What is Machine Learning?

Definition:

- Arthur Samuel (1959): Field of study that gives computers the ability to learn without being explicitly programmed.
- Tom Mitchell (1998): Well-posed Learning Problem: A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E.

ML Algos:

- Supervised learning
- Unsupervised

Others: Reinforcement learning, recommender systems.

——————————————————————————————————————————————————————————————————————————————————————————————————————————————

Supervised Learning:

- Ex. Housing price prediction: an algorithm may draw a line/curve to the graph of housing price data (regression)
- Supervised learning has the right answers given
- Classification (Discrete valued output like 0 or 1)
+ Drawing a boundary between the two classes instead of size of best fit
+ features of each item increase accuracy
+ infinite features? use support vector machine

——————————————————————————————————————————————————————————————————————————————————————————————————————————————

Unsupervised Learning:

- The right answer is not given, but a structure must still be made (i.e. Clustering algorithms where data is separated into groups, such as Google News)
+ Google News splits articles into groups that cover the same story
+ other examples include computing clusters, social network analysis, astronomical data analysis and market segmentation

- ex. cocktail party problem
+ imagine microphones at a party, the microphones will pick up different conversations depending on where they are placed.
+ algo will separate the different voices or different sounds
+ algo is [W,s,v] = svd((repmat(sum(x.*x,1), size(x,1),1).*x)*x’);

——————————————————————————————————————————————————————————————————————————————————————————————————————————————

Model Representation (Linear Regression) - Supervised Learning:

- ex. portland oregeon housing prices
+ with supervised learning, we can predict a price or size from an input size or price respectively

- training set is the housing prices
+notation: m = training examples, x = input variable/features, y = output variable/target variable, (x,y) = one training example, (x^(i), y^(i)) = i^th training example

- training set is feed into our learning algorithm, the learning algorithm outputs a hypothesis function (h), that takes in an input and tries to output an estimated value
+ h is a function that maps from x’s to y’s

- but how do we represent h?
+ h(x) = theta_0 + theta_1(x)
+ so a linear function

- why linear (or univariate linear regression)?
+ this is just a start ok, ya gotta learn one variable linear regression before you learn multivariable linear regression

——————————————————————————————————————————————————————————————————————————————————————————————————————————————

Linear Regression with one variable - Cost function

- the hypothesis for one variable is made up of theta_0 and theta_1
+ how to choose theta_0 and theta_1?
+ as these two values change, we get different lines for our hypothesis function
+ how do we get the two variables to fit the data?
+ idea: choose them so that h(x) is close to y for our training examples(x,y)
+ is a minimization problem of (1/2m)(h(x^(i)) - y^(i))^2 [square difference] for every i in training set (1 <= i <= m)
+ this is the square error function
+ mean is halved for the computation of the gradient descent
+ This is a cost function J(theta_0, theta_1) = sum from (1 <= i <= m) of (1/2m)(h(x^(i)) - y^(i))^2 [square difference]
+ squared error function is the most commonly used for linear regression problems

——————————————————————————————————————————————————————————————————————————————————————————————————————————————

Linear Regression with one variable - Cost function Intuition I


- Comparison: h(x) and J(theta_1)
+ h(x) for a fixed theta, is a function of x; J is a function of theta
+ each value of theta changes h(x) which changes J which measures how the h(x) approximates the data

——————————————————————————————————————————————————————————————————————————————————————————————————————————————

Linear Regression with one variable - Cost function Intuition II

- Contour plot or 3d graph of J with respect to its two variables theta_0 and theta_1
+ 3d graph has a minimum point at the most ideal line (ideal being smallest square error)
+ contour plot tells how far away it is form the most ideal line


——————————————————————————————————————————————————————————————————————————————————————————————————————————————

Linear Regression with one variable - Gradient Descent

- A more general algorithm, used also outside of machine learning
- Consider the following problem
+ have some function J
+ want min theta_0, … ,theta_n of the function J
+ outline: start with some values for the thetas and then keep changing them to reduce J (take steps).

- algorithm:

repeat until convergence{
	for all j from 1 … n # for n variables
		temp_j := theta_j - alpha (derivative of J with respect to theta_j)
		# alpha is the “learning rate”, how big the steps are
	for all j from 1 … n # for n variables
		theta_j := temp_j
		# this is to update all the variables simultaneously
}

——————————————————————————————————————————————————————————————————————————————————————————————————————————————

Linear Regression with one variable - Gradient Descent Intuition

- the derivative will move the function forwards or backwards towards a lower point
- alpha can be too big or too small
+ too small and it will take too many steps
+ too big and it can either overshoot the minimum or even fail to diverge

- if you already are at a local minimum, the derivative will be zero and a step will not move the variable
- as we approach a local minimum, gradient descent will automatically take smaller steps for a constant alpha, so alpha can just be a constant.

——————————————————————————————————————————————————————————————————————————————————————————————————————————————

Linear Regression with one variable - Gradient Descent for linear regression

- apply gradient descent to linear regression model
- however, it can end up in local optima
- however the cost function is always going to be a convex function, so there is only one local optima
- called “Batch gradient descent”: each step uses all the training examples

——————————————————————————————————————————————————————————————————————————————————————————————————————————————
Linear Algebra Review - Matrices and Vectors

- a matrix: is a rectangular array of numbers
+ like vectors, but two dimensional instead of one dimensional
+ dimension of matrix = rows(n) x columns(m) = R^(n x m)

- Aij refers to the (i,j)th entry in matrix A, i.e. ith row, jth column

- a vector is a one dimensional array
- y_i = refers to the ith element in a vector (can start at either 1 or 0)

- we, by convention, usually use upper case letters to refer to matrices and lower case letters to refer to vectors

——————————————————————————————————————————————————————————————————————————————————————————————————————————————
Linear Algebra Review - Addition and Scalar Multiplication

- Matrix addition
+ add up each ijth element together
+ only works on Matrices with the same dimensions

- scalar matrix multiplication
+ muliply each element in the matrix by a scalar

- matrix matrix mulitplication
+ can only be performed on matrices with dimensions n x k and k x m
multiply the elements of row i  of matrix A with the column i of matrix B and multiple the first elements with each other, the second elements with each other… etc.

- matrix multiplication properties
+ not commutative i.e. A x B != B x A
+ but associative i.e. (AxB)xC = Ax(BxC)
+ identity matrix (diagonals have 1) multiplied with any other matrix returns that other matrix

- Inverse
+ inverse of a matrix multiplied by itself returns the identity matrix
+ compute with augmented matrix

- Transpose
+ flip matrix along the diagonal

——————————————————————————————————————————————————————————————————————————————————————————————————————————————
Week 2
——————————————————————————————————————————————————————————————————————————————————————————————————————————————
Multiple Features:

- previously we used one feature
- now, we use multiple features (denoted x_1, … ,x_n for n features)
- x^(i) denotes input features of ith training example (a n-dimensional vector)
- x_j^(i) denotes the value of feature j in ith training example

- previously, our hypotehsis was linear
- now it is h_theta (x) = theta_0 + theta_1 x_1 + theta_2 x_2 + … + theta_n x_n
- for convenience of notation, define x_0 = 1.

- so input x is now a vector
- theta is also a vector of theta_0 … theta_n
- can denote in sigma notation or
- (theta)^Transpose x
- ^ this is vector multiplication

- so this is multivariate linear regression

——————————————————————————————————————————————————————————————————————————————————————————————————————————————
Gradient Descent with Multiple Features:

- cost function J becomes a function that takes in a vector theta
- gradient descent is just one with a different cost function and more times for each theta

——————————————————————————————————————————————————————————————————————————————————————————————————————————————
Gradient Descent with Multiple Features - Feature Scaling Example:

- Idea: Make sure features are on a similar scale
- If they’re not, with two features, it will result in a skewed elliptical shape and make gradient descent take longer
- so divide each feature so that they range from 1 to -1 for example, to make gradient descent run faster
- does not have to be exact, but change if it’s too large or too small

- can try mean normalization to make features have approximately zero mean
- for x_n = (x_n - mu)/ S
- where mu is the average value of x_n
- where S is the range or standard deviation

——————————————————————————————————————————————————————————————————————————————————————————————————————————————
Gradient Descent with Multiple Features - Learning Rate:

- “ Debugging”: how to make sure it is working correctly
- choosing alpha (learning rate)

- making sure it works
- graph no. of iterations of GD and min theta of J must become smaller and smaller
- J(theta) should decrease after every iteration
- can also help judge if gradient descent has converged or not, but automatic convergence tests exist, although may not be reliable
- if graph is increasing, use a smaller learning rate, which is also a fix for many graph problems, but alpha should not be too small as it can be slow to converge

——————————————————————————————————————————————————————————————————————————————————————————————————————————————
Gradient Descent with Multiple Features - Features and polynomial regression:

- consider a house we are trying to sell
- frontage is length of front yard (feature 1)
- depth is depth into property (feature 2)
- lets say area determines price
- create new feature x = frontage x depth

- polynomial regression is just using a polynomial function to fit your data
- possible with small change to linear regression
- x_1 = (size)^1 … x_n = (size)^n  if the focus is on one feature. This means that feature scaling is very important
- can also use roots instead of powers
